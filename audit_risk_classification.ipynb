{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Project 2\n",
    "\n",
    "Project Description:\n",
    "- Use same datasets as Project 1.\n",
    "- Preprocess data: Explore data and apply data scaling.\n",
    "\n",
    "Regression Task:\n",
    "- Apply any two models with bagging and any two models with pasting.\n",
    "- Apply any two models with adaboost boosting\n",
    "- Apply one model with gradient boosting\n",
    "- Apply PCA on data and then apply all the models in project 1 again on data you get from PCA. Compare your results with results in project 2. You don't need to apply all the models twice. Just copy the result table from project 1, prepare similar table for all the models after PCA and compare both tables. Does PCA help in getting better results?\n",
    "- Apply deep learning models covered in class\n",
    "\n",
    "Classification Task:\n",
    "- Apply two voting classifiers - one with hard voting and one with soft voting\n",
    "- Apply any two models with bagging and any two models with pasting.\n",
    "- Apply any two models with adaboost boosting\n",
    "- Apply one model with gradient boosting\n",
    "- Apply PCA on data and then apply all the models in project 1 again on data you get from PCA. Compare your results with results in project 1. You don't need to apply all the models twice. Just copy the result table from project 1, prepare similar table for all the models after PCA and compare both tables. Does PCA help in getting better results?\n",
    "- Apply deep learning models covered in class\n",
    "\n",
    "Deliverables:\n",
    "- Use markdown to provide inline comments for this project.\n",
    "- Your outputs should be clearly executed in the notebook i.e. we should not need to rerun the code to obtain the outputs.\n",
    "- Visualization encouraged.\n",
    "- If you are submitting two different files, then please only one group member submit both the files. If you submit two files separately from different accounts, it will be submitted as two different attempts.\n",
    "- If you are submitting two different files, then please follow below naming convetion:\n",
    "    Project2_Regression_GroupXX_Firstname1_Firstname2.ipynb\n",
    "    Project2_Classification_GroupXX_Firstname1_Firstname2.ipynb\n",
    "- If you are submitting single file, then please follow below naming convetion:\n",
    "    Project2_Both_GroupXX_Firstname1_Firstname2.ipynb\n",
    "\n",
    "Questions regarding the project:\n",
    "- We have created a discussion board under Projects folder on e-learning. Create threads over there and post your queries related to project there.\n",
    "- We will also answer queries there. We will not be answering any project related queries through the mail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pandas reading the audit_risk and trial.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>768</th>\n",
       "      <th>769</th>\n",
       "      <th>770</th>\n",
       "      <th>771</th>\n",
       "      <th>772</th>\n",
       "      <th>773</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sector_score</th>\n",
       "      <td>3.89</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.89</td>\n",
       "      <td>...</td>\n",
       "      <td>55.57</td>\n",
       "      <td>55.57</td>\n",
       "      <td>55.57</td>\n",
       "      <td>55.57</td>\n",
       "      <td>55.57</td>\n",
       "      <td>55.57</td>\n",
       "      <td>55.57</td>\n",
       "      <td>55.57</td>\n",
       "      <td>55.57</td>\n",
       "      <td>55.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOCATION_ID</th>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARA_A</th>\n",
       "      <td>4.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>3.98</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score_A</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Risk_A</th>\n",
       "      <td>2.508</td>\n",
       "      <td>0</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.04</td>\n",
       "      <td>2.388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARA_B</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4.83</td>\n",
       "      <td>0.23</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.83</td>\n",
       "      <td>7.41</td>\n",
       "      <td>12.03</td>\n",
       "      <td>11.05</td>\n",
       "      <td>0.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score_B</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Risk_B</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.046</td>\n",
       "      <td>6.48</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.166</td>\n",
       "      <td>2.964</td>\n",
       "      <td>7.218</td>\n",
       "      <td>6.63</td>\n",
       "      <td>0.198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOTAL</th>\n",
       "      <td>6.68</td>\n",
       "      <td>4.83</td>\n",
       "      <td>0.74</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.83</td>\n",
       "      <td>8.51</td>\n",
       "      <td>20.53</td>\n",
       "      <td>19.45</td>\n",
       "      <td>4.97</td>\n",
       "      <td>...</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numbers</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score_B.1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Risk_C</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Money_Value</th>\n",
       "      <td>3.38</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0</td>\n",
       "      <td>11.75</td>\n",
       "      <td>0</td>\n",
       "      <td>2.95</td>\n",
       "      <td>44.95</td>\n",
       "      <td>7.79</td>\n",
       "      <td>7.34</td>\n",
       "      <td>1.93</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score_MV</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Risk_D</th>\n",
       "      <td>0.676</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0</td>\n",
       "      <td>7.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>26.97</td>\n",
       "      <td>3.116</td>\n",
       "      <td>2.936</td>\n",
       "      <td>0.386</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District_Loss</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROB</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RiSk_E</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>History</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prob</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Risk_F</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inherent_Risk</th>\n",
       "      <td>8.574</td>\n",
       "      <td>2.554</td>\n",
       "      <td>1.548</td>\n",
       "      <td>17.53</td>\n",
       "      <td>1.416</td>\n",
       "      <td>2.156</td>\n",
       "      <td>31.774</td>\n",
       "      <td>18.034</td>\n",
       "      <td>17.206</td>\n",
       "      <td>4.372</td>\n",
       "      <td>...</td>\n",
       "      <td>1.674</td>\n",
       "      <td>1.622</td>\n",
       "      <td>1.594</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.578</td>\n",
       "      <td>1.568</td>\n",
       "      <td>1.456</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONTROL_RISK</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Detection_Risk</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Audit_Risk</th>\n",
       "      <td>1.7148</td>\n",
       "      <td>0.5108</td>\n",
       "      <td>0.3096</td>\n",
       "      <td>3.506</td>\n",
       "      <td>0.2832</td>\n",
       "      <td>0.4312</td>\n",
       "      <td>6.3548</td>\n",
       "      <td>3.6068</td>\n",
       "      <td>3.4412</td>\n",
       "      <td>0.8744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3348</td>\n",
       "      <td>0.3244</td>\n",
       "      <td>0.3188</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.3156</td>\n",
       "      <td>0.3136</td>\n",
       "      <td>0.2912</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.2928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Risk</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27 rows × 776 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0       1       2      3       4       5       6       7    \\\n",
       "Sector_score      3.89    3.89    3.89   3.89    3.89    3.89    3.89    3.89   \n",
       "LOCATION_ID         23       6       6      6       6       6       7       8   \n",
       "PARA_A            4.18       0    0.51      0       0       0     1.1     8.5   \n",
       "Score_A            0.6     0.2     0.2    0.2     0.2     0.2     0.4     0.6   \n",
       "Risk_A           2.508       0   0.102      0       0       0    0.44     5.1   \n",
       "PARA_B             2.5    4.83    0.23   10.8    0.08    0.83    7.41   12.03   \n",
       "Score_B            0.2     0.2     0.2    0.6     0.2     0.2     0.4     0.6   \n",
       "Risk_B             0.5   0.966   0.046   6.48   0.016   0.166   2.964   7.218   \n",
       "TOTAL             6.68    4.83    0.74   10.8    0.08    0.83    8.51   20.53   \n",
       "numbers              5       5       5      6       5       5       5     5.5   \n",
       "Score_B.1          0.2     0.2     0.2    0.6     0.2     0.2     0.2     0.4   \n",
       "Risk_C               1       1       1    3.6       1       1       1     2.2   \n",
       "Money_Value       3.38    0.94       0  11.75       0    2.95   44.95    7.79   \n",
       "Score_MV           0.2     0.2     0.2    0.6     0.2     0.2     0.6     0.4   \n",
       "Risk_D           0.676   0.188       0   7.05       0    0.59   26.97   3.116   \n",
       "District_Loss        2       2       2      2       2       2       2       2   \n",
       "PROB               0.2     0.2     0.2    0.2     0.2     0.2     0.2     0.2   \n",
       "RiSk_E             0.4     0.4     0.4    0.4     0.4     0.4     0.4     0.4   \n",
       "History              0       0       0      0       0       0       0       0   \n",
       "Prob               0.2     0.2     0.2    0.2     0.2     0.2     0.2     0.2   \n",
       "Risk_F               0       0       0      0       0       0       0       0   \n",
       "Score              2.4       2       2    4.4       2       2     3.2     4.2   \n",
       "Inherent_Risk    8.574   2.554   1.548  17.53   1.416   2.156  31.774  18.034   \n",
       "CONTROL_RISK       0.4     0.4     0.4    0.4     0.4     0.4     0.4     0.4   \n",
       "Detection_Risk     0.5     0.5     0.5    0.5     0.5     0.5     0.5     0.5   \n",
       "Audit_Risk      1.7148  0.5108  0.3096  3.506  0.2832  0.4312  6.3548  3.6068   \n",
       "Risk                 1       0       0      1       0       0       1       1   \n",
       "\n",
       "                   8       9    ...     766     767     768    769    770  \\\n",
       "Sector_score      3.89    3.89  ...   55.57   55.57   55.57  55.57  55.57   \n",
       "LOCATION_ID          8       8  ...       8      18       9     16     18   \n",
       "PARA_A             8.4    3.98  ...     0.8    0.36    0.44   0.51   0.75   \n",
       "Score_A            0.6     0.6  ...     0.2     0.2     0.2    0.2    0.2   \n",
       "Risk_A            5.04   2.388  ...    0.16   0.072   0.088  0.102   0.15   \n",
       "PARA_B           11.05    0.99  ...    0.57    0.54    0.53    0.5   0.45   \n",
       "Score_B            0.6     0.2  ...     0.2     0.2     0.2    0.2    0.2   \n",
       "Risk_B            6.63   0.198  ...   0.114   0.108   0.106    0.1   0.09   \n",
       "TOTAL            19.45    4.97  ...    1.37     0.9    0.97   1.01    1.2   \n",
       "numbers            5.5       5  ...       5       5       5      5      5   \n",
       "Score_B.1          0.4     0.2  ...     0.2     0.2     0.2    0.2    0.2   \n",
       "Risk_C             2.2       1  ...       1       1       1      1      1   \n",
       "Money_Value       7.34    1.93  ...       0    0.21       0   0.09      0   \n",
       "Score_MV           0.4     0.2  ...     0.2     0.2     0.2    0.2    0.2   \n",
       "Risk_D           2.936   0.386  ...       0   0.042       0  0.018      0   \n",
       "District_Loss        2       2  ...       2       2       2      2      2   \n",
       "PROB               0.2     0.2  ...     0.2     0.2     0.2    0.2    0.2   \n",
       "RiSk_E             0.4     0.4  ...     0.4     0.4     0.4    0.4    0.4   \n",
       "History              0       0  ...       0       0       0      0      0   \n",
       "Prob               0.2     0.2  ...     0.2     0.2     0.2    0.2    0.2   \n",
       "Risk_F               0       0  ...       0       0       0      0      0   \n",
       "Score              4.2     2.4  ...       2       2       2      2      2   \n",
       "Inherent_Risk   17.206   4.372  ...   1.674   1.622   1.594   1.62   1.64   \n",
       "CONTROL_RISK       0.4     0.4  ...     0.4     0.4     0.4    0.4    0.4   \n",
       "Detection_Risk     0.5     0.5  ...     0.5     0.5     0.5    0.5    0.5   \n",
       "Audit_Risk      3.4412  0.8744  ...  0.3348  0.3244  0.3188  0.324  0.328   \n",
       "Risk                 1       0  ...       0       0       0      0      0   \n",
       "\n",
       "                   771     772     773    774     775  \n",
       "Sector_score     55.57   55.57   55.57  55.57   55.57  \n",
       "LOCATION_ID          9      16      14     18      15  \n",
       "PARA_A            0.49    0.47    0.24    0.2       0  \n",
       "Score_A            0.2     0.2     0.2    0.2     0.2  \n",
       "Risk_A           0.098   0.094   0.048   0.04       0  \n",
       "PARA_B             0.4    0.37    0.04      0       0  \n",
       "Score_B            0.2     0.2     0.2    0.2     0.2  \n",
       "Risk_B            0.08   0.074   0.008      0       0  \n",
       "TOTAL             0.89    0.84    0.28    0.2       0  \n",
       "numbers              5       5       5      5       5  \n",
       "Score_B.1          0.2     0.2     0.2    0.2     0.2  \n",
       "Risk_C               1       1       1      1       1  \n",
       "Money_Value          0       0       0      0    0.32  \n",
       "Score_MV           0.2     0.2     0.2    0.2     0.2  \n",
       "Risk_D               0       0       0      0   0.064  \n",
       "District_Loss        2       2       2      2       2  \n",
       "PROB               0.2     0.2     0.2    0.2     0.2  \n",
       "RiSk_E             0.4     0.4     0.4    0.4     0.4  \n",
       "History              0       0       0      0       0  \n",
       "Prob               0.2     0.2     0.2    0.2     0.2  \n",
       "Risk_F               0       0       0      0       0  \n",
       "Score                2       2       2      2       2  \n",
       "Inherent_Risk    1.578   1.568   1.456   1.44   1.464  \n",
       "CONTROL_RISK       0.4     0.4     0.4    0.4     0.4  \n",
       "Detection_Risk     0.5     0.5     0.5    0.5     0.5  \n",
       "Audit_Risk      0.3156  0.3136  0.2912  0.288  0.2928  \n",
       "Risk                 0       0       0      0       0  \n",
       "\n",
       "[27 rows x 776 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit_risk_df = pd.read_csv(\"audit_risk.csv\")\n",
    "trial_df = pd.read_csv(\"trial.csv\")\n",
    "audit_risk_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_risk_df.rename(columns={'PROB': 'PROB1'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sector_score', 'LOCATION_ID', 'PARA_A', 'Score_A', 'Risk_A', 'PARA_B',\n",
      "       'Score_B', 'Risk_B', 'TOTAL', 'numbers', 'Score_B.1', 'Risk_C',\n",
      "       'Money_Value', 'Score_MV', 'Risk_D', 'District_Loss', 'PROB1', 'RiSk_E',\n",
      "       'History', 'Prob', 'Risk_F', 'Score', 'Inherent_Risk', 'CONTROL_RISK',\n",
      "       'Detection_Risk', 'Audit_Risk', 'Risk'],\n",
      "      dtype='object')\n",
      "Index(['Sector_score', 'LOCATION_ID', 'PARA_A', 'SCORE_A', 'PARA_B', 'SCORE_B',\n",
      "       'TOTAL', 'numbers', 'Marks', 'Money_Value', 'MONEY_Marks', 'District',\n",
      "       'Loss', 'LOSS_SCORE', 'History', 'History_score', 'Score', 'Risk'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(audit_risk_df.columns)\n",
    "print(trial_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After reading the two datasets the following observations were made : \n",
    "\n",
    "## Detection_Risk is a constant value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_risk_df = audit_risk_df.drop(\"Detection_Risk\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector_score</th>\n",
       "      <th>LOCATION_ID</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>SCORE_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>SCORE_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>Marks</th>\n",
       "      <th>Money_Value</th>\n",
       "      <th>MONEY_Marks</th>\n",
       "      <th>District</th>\n",
       "      <th>Loss</th>\n",
       "      <th>LOSS_SCORE</th>\n",
       "      <th>History</th>\n",
       "      <th>History_score</th>\n",
       "      <th>Score</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.89</td>\n",
       "      <td>23</td>\n",
       "      <td>4.18</td>\n",
       "      <td>6</td>\n",
       "      <td>2.5000</td>\n",
       "      <td>2</td>\n",
       "      <td>6.6800</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.380</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>4.8300</td>\n",
       "      <td>2</td>\n",
       "      <td>4.8300</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.940</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.51</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>10.8000</td>\n",
       "      <td>6</td>\n",
       "      <td>10.8000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>11.750</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.950</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.89</td>\n",
       "      <td>7</td>\n",
       "      <td>1.10</td>\n",
       "      <td>4</td>\n",
       "      <td>7.4100</td>\n",
       "      <td>4</td>\n",
       "      <td>8.5100</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>44.950</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.89</td>\n",
       "      <td>8</td>\n",
       "      <td>8.50</td>\n",
       "      <td>6</td>\n",
       "      <td>12.0300</td>\n",
       "      <td>6</td>\n",
       "      <td>20.5300</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4</td>\n",
       "      <td>7.790</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.89</td>\n",
       "      <td>8</td>\n",
       "      <td>8.40</td>\n",
       "      <td>6</td>\n",
       "      <td>11.0500</td>\n",
       "      <td>6</td>\n",
       "      <td>19.4500</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4</td>\n",
       "      <td>7.340</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.89</td>\n",
       "      <td>8</td>\n",
       "      <td>3.98</td>\n",
       "      <td>6</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>2</td>\n",
       "      <td>4.9700</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.930</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.89</td>\n",
       "      <td>8</td>\n",
       "      <td>5.43</td>\n",
       "      <td>6</td>\n",
       "      <td>10.7700</td>\n",
       "      <td>6</td>\n",
       "      <td>16.2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.420</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.89</td>\n",
       "      <td>8</td>\n",
       "      <td>15.38</td>\n",
       "      <td>6</td>\n",
       "      <td>40.1400</td>\n",
       "      <td>6</td>\n",
       "      <td>55.5200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.960</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.89</td>\n",
       "      <td>8</td>\n",
       "      <td>5.47</td>\n",
       "      <td>6</td>\n",
       "      <td>7.6300</td>\n",
       "      <td>4</td>\n",
       "      <td>13.1000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.430</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.89</td>\n",
       "      <td>8</td>\n",
       "      <td>1.09</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>2</td>\n",
       "      <td>1.4400</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.89</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.89</td>\n",
       "      <td>13</td>\n",
       "      <td>1.95</td>\n",
       "      <td>4</td>\n",
       "      <td>9.0100</td>\n",
       "      <td>4</td>\n",
       "      <td>10.9600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9.000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.89</td>\n",
       "      <td>37</td>\n",
       "      <td>8.54</td>\n",
       "      <td>6</td>\n",
       "      <td>31.6300</td>\n",
       "      <td>6</td>\n",
       "      <td>40.1700</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>41.280</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.89</td>\n",
       "      <td>37</td>\n",
       "      <td>4.18</td>\n",
       "      <td>6</td>\n",
       "      <td>4.8300</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0100</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4</td>\n",
       "      <td>14.030</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.89</td>\n",
       "      <td>37</td>\n",
       "      <td>1.81</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0300</td>\n",
       "      <td>2</td>\n",
       "      <td>2.8400</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.89</td>\n",
       "      <td>37</td>\n",
       "      <td>4.86</td>\n",
       "      <td>6</td>\n",
       "      <td>46.7800</td>\n",
       "      <td>6</td>\n",
       "      <td>51.6400</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4</td>\n",
       "      <td>63.180</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.89</td>\n",
       "      <td>24</td>\n",
       "      <td>6.26</td>\n",
       "      <td>6</td>\n",
       "      <td>14.1000</td>\n",
       "      <td>6</td>\n",
       "      <td>20.3600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>34.240</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.89</td>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2</td>\n",
       "      <td>5.9400</td>\n",
       "      <td>4</td>\n",
       "      <td>5.9600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.89</td>\n",
       "      <td>3</td>\n",
       "      <td>5.31</td>\n",
       "      <td>6</td>\n",
       "      <td>22.7900</td>\n",
       "      <td>6</td>\n",
       "      <td>28.1000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>205.190</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.89</td>\n",
       "      <td>3</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.89</td>\n",
       "      <td>4</td>\n",
       "      <td>5.78</td>\n",
       "      <td>6</td>\n",
       "      <td>57.9200</td>\n",
       "      <td>6</td>\n",
       "      <td>63.7000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.160</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.89</td>\n",
       "      <td>4</td>\n",
       "      <td>7.42</td>\n",
       "      <td>6</td>\n",
       "      <td>2.2400</td>\n",
       "      <td>2</td>\n",
       "      <td>9.6600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.89</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.1000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.89</td>\n",
       "      <td>14</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6</td>\n",
       "      <td>31.7600</td>\n",
       "      <td>6</td>\n",
       "      <td>38.6100</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.460</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.89</td>\n",
       "      <td>14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0300</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0300</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.89</td>\n",
       "      <td>37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.780</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>55.57</td>\n",
       "      <td>13</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2517</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>55.57</td>\n",
       "      <td>13</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3115</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>55.57</td>\n",
       "      <td>13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>55.57</td>\n",
       "      <td>13</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>55.57</td>\n",
       "      <td>13</td>\n",
       "      <td>1.09</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0900</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>55.57</td>\n",
       "      <td>13</td>\n",
       "      <td>1.29</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2900</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>55.57</td>\n",
       "      <td>13</td>\n",
       "      <td>0.51</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>55.57</td>\n",
       "      <td>21</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>55.57</td>\n",
       "      <td>18</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>2</td>\n",
       "      <td>1.3000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>55.57</td>\n",
       "      <td>21</td>\n",
       "      <td>1.07</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0700</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>55.57</td>\n",
       "      <td>25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>55.57</td>\n",
       "      <td>32</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "      <td>2.9700</td>\n",
       "      <td>6</td>\n",
       "      <td>3.4700</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.180</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>55.57</td>\n",
       "      <td>22</td>\n",
       "      <td>0.49</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0400</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>55.57</td>\n",
       "      <td>14</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>2</td>\n",
       "      <td>1.4900</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>55.57</td>\n",
       "      <td>12</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2</td>\n",
       "      <td>1.1100</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0100</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>55.57</td>\n",
       "      <td>12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>55.57</td>\n",
       "      <td>14</td>\n",
       "      <td>0.59</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5900</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>55.57</td>\n",
       "      <td>36</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>55.57</td>\n",
       "      <td>14</td>\n",
       "      <td>1.48</td>\n",
       "      <td>4</td>\n",
       "      <td>4.4800</td>\n",
       "      <td>6</td>\n",
       "      <td>5.9600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>55.57</td>\n",
       "      <td>22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>3.3000</td>\n",
       "      <td>6</td>\n",
       "      <td>3.3000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>55.57</td>\n",
       "      <td>8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5700</td>\n",
       "      <td>2</td>\n",
       "      <td>1.3700</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>55.57</td>\n",
       "      <td>18</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.210</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>55.57</td>\n",
       "      <td>9</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>55.57</td>\n",
       "      <td>16</td>\n",
       "      <td>0.51</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0100</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.090</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>55.57</td>\n",
       "      <td>18</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>55.57</td>\n",
       "      <td>9</td>\n",
       "      <td>0.49</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>55.57</td>\n",
       "      <td>16</td>\n",
       "      <td>0.47</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>55.57</td>\n",
       "      <td>14</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>55.57</td>\n",
       "      <td>18</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>55.57</td>\n",
       "      <td>15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.320</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>776 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sector_score LOCATION_ID  PARA_A  SCORE_A   PARA_B  SCORE_B    TOTAL  \\\n",
       "0            3.89          23    4.18        6   2.5000        2   6.6800   \n",
       "1            3.89           6    0.00        2   4.8300        2   4.8300   \n",
       "2            3.89           6    0.51        2   0.2300        2   0.7400   \n",
       "3            3.89           6    0.00        2  10.8000        6  10.8000   \n",
       "4            3.89           6    0.00        2   0.0800        2   0.0800   \n",
       "5            3.89           6    0.00        2   0.8300        2   0.8300   \n",
       "6            3.89           7    1.10        4   7.4100        4   8.5100   \n",
       "7            3.89           8    8.50        6  12.0300        6  20.5300   \n",
       "8            3.89           8    8.40        6  11.0500        6  19.4500   \n",
       "9            3.89           8    3.98        6   0.9900        2   4.9700   \n",
       "10           3.89           8    5.43        6  10.7700        6  16.2000   \n",
       "11           3.89           8   15.38        6  40.1400        6  55.5200   \n",
       "12           3.89           8    5.47        6   7.6300        4  13.1000   \n",
       "13           3.89           8    1.09        4   0.3500        2   1.4400   \n",
       "14           3.89           8    0.00        2   0.8400        2   0.8400   \n",
       "15           3.89          13    1.95        4   9.0100        4  10.9600   \n",
       "16           3.89          37    8.54        6  31.6300        6  40.1700   \n",
       "17           3.89          37    4.18        6   4.8300        2   9.0100   \n",
       "18           3.89          37    1.81        4   1.0300        2   2.8400   \n",
       "19           3.89          37    4.86        6  46.7800        6  51.6400   \n",
       "20           3.89          24    6.26        6  14.1000        6  20.3600   \n",
       "21           3.89           3    0.02        2   5.9400        4   5.9600   \n",
       "22           3.89           3    5.31        6  22.7900        6  28.1000   \n",
       "23           3.89           3    0.94        2   0.0100        2   0.9500   \n",
       "24           3.89           4    5.78        6  57.9200        6  63.7000   \n",
       "25           3.89           4    7.42        6   2.2400        2   9.6600   \n",
       "26           3.89           4    0.00        2   1.1000        2   1.1000   \n",
       "27           3.89          14    6.85        6  31.7600        6  38.6100   \n",
       "28           3.89          14    0.00        2   1.0300        2   1.0300   \n",
       "29           3.89          37    0.00        2   0.7500        2   0.7500   \n",
       "..            ...         ...     ...      ...      ...      ...      ...   \n",
       "746         55.57          13    0.25        2   0.0017        2   0.2517   \n",
       "747         55.57          13    0.31        2   0.0015        2   0.3115   \n",
       "748         55.57          13    0.00        2   0.0000        2   0.0000   \n",
       "749         55.57          13    0.84        2   0.0000        2   0.8400   \n",
       "750         55.57          13    1.09        4   0.0000        2   1.0900   \n",
       "751         55.57          13    1.29        4   0.0000        2   1.2900   \n",
       "752         55.57          13    0.51        2   0.3700        2   0.8800   \n",
       "753         55.57          21    0.09        2   0.0000        2   0.0900   \n",
       "754         55.57          18    0.39        2   0.9100        2   1.3000   \n",
       "755         55.57          21    1.07        4   0.0000        2   1.0700   \n",
       "756         55.57          25    0.00        2   0.0000        2   0.0000   \n",
       "757         55.57          32    0.50        2   2.9700        6   3.4700   \n",
       "758         55.57          22    0.49        2   0.5500        2   1.0400   \n",
       "759         55.57          14    0.84        2   0.6500        2   1.4900   \n",
       "760         55.57          12    0.90        2   1.1100        4   2.0100   \n",
       "761         55.57          12    0.00        2   0.0000        2   0.0000   \n",
       "762         55.57          14    0.59        2   0.0000        2   0.5900   \n",
       "763         55.57          36    0.02        2   0.0000        2   0.0200   \n",
       "764         55.57          14    1.48        4   4.4800        6   5.9600   \n",
       "765         55.57          22    0.00        2   3.3000        6   3.3000   \n",
       "766         55.57           8    0.80        2   0.5700        2   1.3700   \n",
       "767         55.57          18    0.36        2   0.5400        2   0.9000   \n",
       "768         55.57           9    0.44        2   0.5300        2   0.9700   \n",
       "769         55.57          16    0.51        2   0.5000        2   1.0100   \n",
       "770         55.57          18    0.75        2   0.4500        2   1.2000   \n",
       "771         55.57           9    0.49        2   0.4000        2   0.8900   \n",
       "772         55.57          16    0.47        2   0.3700        2   0.8400   \n",
       "773         55.57          14    0.24        2   0.0400        2   0.2800   \n",
       "774         55.57          18    0.20        2   0.0000        2   0.2000   \n",
       "775         55.57          15    0.00        2   0.0000        2   0.0000   \n",
       "\n",
       "     numbers  Marks  Money_Value  MONEY_Marks  District  Loss  LOSS_SCORE  \\\n",
       "0        5.0      2        3.380            2         2     0           2   \n",
       "1        5.0      2        0.940            2         2     0           2   \n",
       "2        5.0      2        0.000            2         2     0           2   \n",
       "3        6.0      6       11.750            6         2     0           2   \n",
       "4        5.0      2        0.000            2         2     0           2   \n",
       "5        5.0      2        2.950            2         2     0           2   \n",
       "6        5.0      2       44.950            6         2     0           2   \n",
       "7        5.5      4        7.790            4         2     0           2   \n",
       "8        5.5      4        7.340            4         2     0           2   \n",
       "9        5.0      2        1.930            2         2     0           2   \n",
       "10       5.0      2        4.420            2         2     0           2   \n",
       "11       5.0      2        0.960            2         2     1           4   \n",
       "12       5.0      2       10.430            6         2     0           2   \n",
       "13       5.0      2        0.000            2         2     0           2   \n",
       "14       5.0      2        0.007            2         2     0           2   \n",
       "15       5.0      2        9.000            4         2     0           2   \n",
       "16       5.0      2       41.280            6         2     0           2   \n",
       "17       5.5      4       14.030            6         2     0           2   \n",
       "18       5.0      2        0.000            2         2     0           2   \n",
       "19       5.5      4       63.180            6         2     0           2   \n",
       "20       5.0      2       34.240            6         2     0           2   \n",
       "21       5.0      2        0.010            2         2     0           2   \n",
       "22       5.0      2      205.190            6         2     0           2   \n",
       "23       5.0      2        0.100            2         2     0           2   \n",
       "24       5.0      2       11.160            6         2     0           2   \n",
       "25       5.0      2        1.250            2         2     0           2   \n",
       "26       5.0      2        0.007            2         2     0           2   \n",
       "27       5.0      2        1.460            2         2     0           2   \n",
       "28       5.0      2        0.000            2         2     0           2   \n",
       "29       5.0      2        6.780            4         2     0           2   \n",
       "..       ...    ...          ...          ...       ...   ...         ...   \n",
       "746      5.0      2        0.000            2         2     0           2   \n",
       "747      5.0      2        0.000            2         2     0           2   \n",
       "748      5.0      2        0.000            2         2     0           2   \n",
       "749      5.0      2        0.000            2         2     0           2   \n",
       "750      5.0      2        0.000            2         2     0           2   \n",
       "751      5.0      2        0.000            2         2     0           2   \n",
       "752      5.0      2        0.000            2         2     0           2   \n",
       "753      5.0      2        0.000            2         2     0           2   \n",
       "754      5.0      2        0.000            2         2     0           2   \n",
       "755      5.0      2        0.000            2         2     0           2   \n",
       "756      5.0      2        0.000            2         2     0           2   \n",
       "757      5.0      2        0.180            2         2     0           2   \n",
       "758      5.0      2        0.000            2         2     0           2   \n",
       "759      5.0      2        0.000            2         2     0           2   \n",
       "760      5.0      2        0.000            2         2     0           2   \n",
       "761      5.0      2        0.000            2         2     0           2   \n",
       "762      5.0      2        0.000            2         2     0           2   \n",
       "763      5.0      2        0.000            2         2     0           2   \n",
       "764      5.0      2        0.000            2         2     0           2   \n",
       "765      5.0      2        0.000            2         2     0           2   \n",
       "766      5.0      2        0.000            2         2     0           2   \n",
       "767      5.0      2        0.210            2         2     0           2   \n",
       "768      5.0      2        0.000            2         2     0           2   \n",
       "769      5.0      2        0.090            2         2     0           2   \n",
       "770      5.0      2        0.000            2         2     0           2   \n",
       "771      5.0      2        0.000            2         2     0           2   \n",
       "772      5.0      2        0.000            2         2     0           2   \n",
       "773      5.0      2        0.000            2         2     0           2   \n",
       "774      5.0      2        0.000            2         2     0           2   \n",
       "775      5.0      2        0.320            2         2     0           2   \n",
       "\n",
       "     History  History_score  Score  Risk  \n",
       "0          0              2    2.4     1  \n",
       "1          0              2    2.0     0  \n",
       "2          0              2    2.0     0  \n",
       "3          0              2    4.4     1  \n",
       "4          0              2    2.0     0  \n",
       "5          0              2    2.0     0  \n",
       "6          0              2    3.2     1  \n",
       "7          0              2    4.2     1  \n",
       "8          0              2    4.2     1  \n",
       "9          0              2    2.4     1  \n",
       "10         0              2    3.6     1  \n",
       "11         1              4    4.0     1  \n",
       "12         1              4    3.6     1  \n",
       "13         0              2    2.2     1  \n",
       "14         0              2    2.0     0  \n",
       "15         0              2    3.0     1  \n",
       "16         1              4    4.2     1  \n",
       "17         0              2    3.2     1  \n",
       "18         0              2    2.2     1  \n",
       "19         0              2    4.4     1  \n",
       "20         1              4    4.2     1  \n",
       "21         0              2    2.6     1  \n",
       "22         1              4    4.2     1  \n",
       "23         0              2    2.0     0  \n",
       "24         0              2    4.0     1  \n",
       "25         0              2    2.4     1  \n",
       "26         0              2    2.0     0  \n",
       "27         0              2    3.6     1  \n",
       "28         0              2    2.0     0  \n",
       "29         0              2    2.2     1  \n",
       "..       ...            ...    ...   ...  \n",
       "746        0              2    2.0     0  \n",
       "747        0              2    2.0     0  \n",
       "748        0              2    2.0     0  \n",
       "749        0              2    2.0     0  \n",
       "750        0              2    2.2     1  \n",
       "751        0              2    2.2     1  \n",
       "752        0              2    2.0     0  \n",
       "753        0              2    2.0     0  \n",
       "754        0              2    2.0     0  \n",
       "755        0              2    2.2     1  \n",
       "756        0              2    2.0     0  \n",
       "757        0              2    3.2     1  \n",
       "758        0              2    2.0     0  \n",
       "759        0              2    2.0     0  \n",
       "760        0              2    2.6     1  \n",
       "761        0              2    2.0     0  \n",
       "762        0              2    2.0     0  \n",
       "763        0              2    2.0     0  \n",
       "764        0              2    3.4     1  \n",
       "765        0              2    3.2     1  \n",
       "766        0              2    2.0     0  \n",
       "767        0              2    2.0     0  \n",
       "768        0              2    2.0     0  \n",
       "769        0              2    2.0     0  \n",
       "770        0              2    2.0     0  \n",
       "771        0              2    2.0     0  \n",
       "772        0              2    2.0     0  \n",
       "773        0              2    2.0     0  \n",
       "774        0              2    2.0     0  \n",
       "775        0              2    2.0     0  \n",
       "\n",
       "[776 rows x 18 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCORE_A and SCORE_B in trial_df are 10* Score_A and 10*Score_B of audit_risk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_risk_df[\"Score_A\"] = audit_risk_df[\"Score_A\"]*10\n",
    "audit_risk_df[\"Score_B\"] = audit_risk_df[\"Score_B\"]*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c_with_risk_cols = ['Sector_score', 'LOCATION_ID', 'PARA_A', 'Score_A', 'PARA_B', 'Score_B', 'TOTAL', 'numbers', 'Money_Value', 'History','Score', 'Risk']\n",
    "c_without_risk_cols = ['Sector_score', 'LOCATION_ID', 'PARA_A', 'Score_A', 'PARA_B', 'Score_B', 'TOTAL', 'numbers', 'Money_Value', 'History','Score']\n",
    "c_with_risk_cols_upper = [x.upper() for x in c_with_risk_cols]\n",
    "c_without_risk_cols_upper = [x.upper() for x in c_without_risk_cols]\n",
    "\n",
    "audit_names = audit_risk_df.columns\n",
    "audit_names_upper =  [x.upper() for x in audit_names]\n",
    "audit_risk_df.columns = audit_names_upper\n",
    "\n",
    "trial_names = trial_df.columns\n",
    "trial_names_upper =  [x.upper() for x in trial_names]\n",
    "trial_df.columns = trial_names_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "L= ['SECTOR_SCORE', 'LOCATION_ID', 'PARA_A', 'SCORE_A', 'PARA_B', 'SCORE_B', 'TOTAL', 'NUMBERS', 'MONEY_VALUE', 'HISTORY','SCORE', 'RISK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_risk = audit_risk_df.merge(trial_df, on=L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit_risk['RISK'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_risk = audit_risk.drop([\"MONEY_MARKS\",\"DISTRICT\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 629 entries, 0 to 628\n",
      "Data columns (total 30 columns):\n",
      "SECTOR_SCORE     629 non-null float64\n",
      "LOCATION_ID      629 non-null object\n",
      "PARA_A           629 non-null float64\n",
      "SCORE_A          629 non-null float64\n",
      "RISK_A           629 non-null float64\n",
      "PARA_B           629 non-null float64\n",
      "SCORE_B          629 non-null float64\n",
      "RISK_B           629 non-null float64\n",
      "TOTAL            629 non-null float64\n",
      "NUMBERS          629 non-null float64\n",
      "SCORE_B.1        629 non-null float64\n",
      "RISK_C           629 non-null float64\n",
      "MONEY_VALUE      628 non-null float64\n",
      "SCORE_MV         629 non-null float64\n",
      "RISK_D           629 non-null float64\n",
      "DISTRICT_LOSS    629 non-null int64\n",
      "PROB1            629 non-null float64\n",
      "RISK_E           629 non-null float64\n",
      "HISTORY          629 non-null int64\n",
      "PROB             629 non-null float64\n",
      "RISK_F           629 non-null float64\n",
      "SCORE            629 non-null float64\n",
      "INHERENT_RISK    629 non-null float64\n",
      "CONTROL_RISK     629 non-null float64\n",
      "AUDIT_RISK       629 non-null float64\n",
      "RISK             629 non-null int64\n",
      "MARKS            629 non-null int64\n",
      "LOSS             629 non-null int64\n",
      "LOSS_SCORE       629 non-null int64\n",
      "HISTORY_SCORE    629 non-null int64\n",
      "dtypes: float64(22), int64(7), object(1)\n",
      "memory usage: 152.3+ KB\n"
     ]
    }
   ],
   "source": [
    "audit_risk.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SECTOR_SCORE     0\n",
       "LOCATION_ID      0\n",
       "PARA_A           0\n",
       "SCORE_A          0\n",
       "RISK_A           0\n",
       "PARA_B           0\n",
       "SCORE_B          0\n",
       "RISK_B           0\n",
       "TOTAL            0\n",
       "NUMBERS          0\n",
       "SCORE_B.1        0\n",
       "RISK_C           0\n",
       "MONEY_VALUE      0\n",
       "SCORE_MV         0\n",
       "RISK_D           0\n",
       "DISTRICT_LOSS    0\n",
       "PROB1            0\n",
       "RISK_E           0\n",
       "HISTORY          0\n",
       "PROB             0\n",
       "RISK_F           0\n",
       "SCORE            0\n",
       "INHERENT_RISK    0\n",
       "CONTROL_RISK     0\n",
       "AUDIT_RISK       0\n",
       "RISK             0\n",
       "MARKS            0\n",
       "LOSS             0\n",
       "LOSS_SCORE       0\n",
       "HISTORY_SCORE    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit_risk['MONEY_VALUE'] = audit_risk[\"MONEY_VALUE\"].fillna(audit_risk[\"MONEY_VALUE\"].mean())\n",
    "# merged_data_sans_dup = merged_data_sans_dup[\"Money_Value\"].fillna(merged_data_sans_dup[\"Money_Value\"].median())\n",
    "\n",
    "audit_risk.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_risk[\"LOCATION_ID\"]= audit_risk[\"LOCATION_ID\"].replace(\"LOHARU\", 45)\n",
    "audit_risk[\"LOCATION_ID\"]= audit_risk[\"LOCATION_ID\"].replace(\"NUH\", 46)\n",
    "audit_risk[\"LOCATION_ID\"]= audit_risk[\"LOCATION_ID\"].replace(\"SAFIDON\", 47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(629, 30)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sans_out = audit_risk[audit_risk.PARA_B != 1264.630000]\n",
    "audit_risk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONEY_VALUE</th>\n",
       "      <th>RISK_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>628.000000</td>\n",
       "      <td>628.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.235104</td>\n",
       "      <td>10.114415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>73.623456</td>\n",
       "      <td>44.213178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.107500</td>\n",
       "      <td>3.585000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>935.030000</td>\n",
       "      <td>561.018000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MONEY_VALUE      RISK_D\n",
       "count   628.000000  628.000000\n",
       "mean     17.235104   10.114415\n",
       "std      73.623456   44.213178\n",
       "min       0.000000    0.000000\n",
       "25%       0.000000    0.000000\n",
       "50%       0.140000    0.027000\n",
       "75%       9.107500    3.585000\n",
       "max     935.030000  561.018000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sans_out[['MONEY_VALUE','RISK_D']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SECTOR_SCORE</th>\n",
       "      <th>LOCATION_ID</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>SCORE_A</th>\n",
       "      <th>RISK_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>SCORE_B</th>\n",
       "      <th>RISK_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>NUMBERS</th>\n",
       "      <th>...</th>\n",
       "      <th>RISK_F</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>INHERENT_RISK</th>\n",
       "      <th>CONTROL_RISK</th>\n",
       "      <th>AUDIT_RISK</th>\n",
       "      <th>RISK</th>\n",
       "      <th>MARKS</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>LOSS_SCORE</th>\n",
       "      <th>HISTORY_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3.89</td>\n",
       "      <td>19</td>\n",
       "      <td>7.97</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.782</td>\n",
       "      <td>17.18</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.308</td>\n",
       "      <td>25.15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>577.508</td>\n",
       "      <td>0.4</td>\n",
       "      <td>115.5016</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>1.99</td>\n",
       "      <td>2</td>\n",
       "      <td>57.03</td>\n",
       "      <td>6.0</td>\n",
       "      <td>34.218</td>\n",
       "      <td>134.33</td>\n",
       "      <td>6.0</td>\n",
       "      <td>80.598</td>\n",
       "      <td>191.36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>622.838</td>\n",
       "      <td>0.4</td>\n",
       "      <td>124.5676</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SECTOR_SCORE LOCATION_ID  PARA_A  SCORE_A  RISK_A  PARA_B  SCORE_B  \\\n",
       "34           3.89          19    7.97      6.0   4.782   17.18      6.0   \n",
       "288          1.99           2   57.03      6.0  34.218  134.33      6.0   \n",
       "\n",
       "     RISK_B   TOTAL  NUMBERS  ...  RISK_F  SCORE  INHERENT_RISK  CONTROL_RISK  \\\n",
       "34   10.308   25.15      5.0  ...     0.0    4.0        577.508           0.4   \n",
       "288  80.598  191.36      5.0  ...     0.0    4.0        622.838           0.4   \n",
       "\n",
       "     AUDIT_RISK  RISK  MARKS  LOSS  LOSS_SCORE  HISTORY_SCORE  \n",
       "34     115.5016     1      2     0           2              2  \n",
       "288    124.5676     1      2     0           2              2  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sans_out[(sans_out['INHERENT_RISK'] == 622.838000) | (sans_out['TOTAL'] == 191.360000) | (sans_out['MONEY_VALUE'] == 935.030000) |(sans_out['RISK_D'] == 561.018000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = sans_out[(sans_out['INHERENT_RISK'] != 622.838000) & (sans_out['TOTAL'] != 191.360000) & (sans_out['MONEY_VALUE'] != 935.030000) & (sans_out['RISK_D'] != 561.018000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SECTOR_SCORE     False\n",
       "LOCATION_ID      False\n",
       "PARA_A           False\n",
       "SCORE_A          False\n",
       "RISK_A           False\n",
       "PARA_B           False\n",
       "SCORE_B          False\n",
       "RISK_B           False\n",
       "TOTAL            False\n",
       "NUMBERS          False\n",
       "SCORE_B.1        False\n",
       "RISK_C           False\n",
       "MONEY_VALUE      False\n",
       "SCORE_MV         False\n",
       "RISK_D           False\n",
       "DISTRICT_LOSS    False\n",
       "PROB1            False\n",
       "RISK_E           False\n",
       "HISTORY          False\n",
       "PROB             False\n",
       "RISK_F           False\n",
       "SCORE            False\n",
       "INHERENT_RISK    False\n",
       "CONTROL_RISK     False\n",
       "AUDIT_RISK       False\n",
       "RISK             False\n",
       "MARKS            False\n",
       "LOSS             False\n",
       "LOSS_SCORE       False\n",
       "HISTORY_SCORE    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape\n",
    "final_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SECTOR_SCORE', 'LOCATION_ID', 'PARA_A', 'SCORE_A', 'RISK_A', 'PARA_B',\n",
       "       'SCORE_B', 'RISK_B', 'TOTAL', 'NUMBERS', 'SCORE_B.1', 'RISK_C',\n",
       "       'MONEY_VALUE', 'SCORE_MV', 'RISK_D', 'DISTRICT_LOSS', 'PROB1', 'RISK_E',\n",
       "       'HISTORY', 'PROB', 'RISK_F', 'SCORE', 'INHERENT_RISK', 'CONTROL_RISK',\n",
       "       'AUDIT_RISK', 'RISK', 'MARKS', 'LOSS', 'LOSS_SCORE', 'HISTORY_SCORE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['RISK'].unique()\n",
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "Audit_risk = final_df.copy()\n",
    "mm_scaler = MinMaxScaler()\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "y_final_reg = final_df['AUDIT_RISK']# Regression y\n",
    "\n",
    "y_final_clf = final_df['RISK'] # Classification y\n",
    "to_scale_x_df = Audit_risk.drop([\"AUDIT_RISK\",\"RISK\"], axis =1)\n",
    "\n",
    "mm_x_df = to_scale_x_df.copy()\n",
    "std_x_df = to_scale_x_df.copy()\n",
    "\n",
    "num_cols = ['SECTOR_SCORE', 'LOCATION_ID','PARA_A', 'SCORE_A', 'RISK_A', 'PARA_B',\n",
    "       'SCORE_B', 'RISK_B', 'TOTAL', 'NUMBERS', 'SCORE_B.1', 'RISK_C',\n",
    "       'MONEY_VALUE', 'SCORE_MV', 'RISK_D', 'DISTRICT_LOSS', 'PROB1', 'RISK_E',\n",
    "       'HISTORY', 'PROB', 'RISK_F', 'SCORE', 'INHERENT_RISK', 'CONTROL_RISK',\n",
    "        'MARKS', 'LOSS', 'LOSS_SCORE', 'HISTORY_SCORE']\n",
    "num_cols = [x.upper() for x in num_cols]\n",
    "\n",
    "mm_x_df[num_cols] = mm_scaler.fit_transform(mm_x_df[num_cols])       # MinMax scaled X\n",
    "std_x_df[num_cols] = std_scaler.fit_transform(std_x_df[num_cols])    # Std scaled X\n",
    "X=mm_x_df[num_cols]\n",
    "y=y_final_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SECTOR_SCORE</th>\n",
       "      <th>LOCATION_ID</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>SCORE_A</th>\n",
       "      <th>RISK_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>SCORE_B</th>\n",
       "      <th>RISK_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>NUMBERS</th>\n",
       "      <th>...</th>\n",
       "      <th>HISTORY</th>\n",
       "      <th>PROB</th>\n",
       "      <th>RISK_F</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>INHERENT_RISK</th>\n",
       "      <th>CONTROL_RISK</th>\n",
       "      <th>MARKS</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>LOSS_SCORE</th>\n",
       "      <th>HISTORY_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.049176</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.049176</td>\n",
       "      <td>0.017314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.045065</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.012320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011150</td>\n",
       "      <td>0.032584</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.004992</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074797</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.074797</td>\n",
       "      <td>0.072860</td>\n",
       "      <td>0.250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.027701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.005599</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.008627</td>\n",
       "      <td>0.051319</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.034213</td>\n",
       "      <td>0.057411</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.052163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.083316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.083316</td>\n",
       "      <td>0.138501</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.028567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.098824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.098824</td>\n",
       "      <td>0.076529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.076529</td>\n",
       "      <td>0.131215</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.027145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.063882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.063882</td>\n",
       "      <td>0.074590</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.074590</td>\n",
       "      <td>0.109290</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.018211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.180941</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.180941</td>\n",
       "      <td>0.277997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.277997</td>\n",
       "      <td>0.374553</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.058912</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.064353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.064353</td>\n",
       "      <td>0.052843</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.035229</td>\n",
       "      <td>0.088376</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.022312</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.022941</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.015294</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.041600</td>\n",
       "      <td>0.073939</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.013711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.100471</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100471</td>\n",
       "      <td>0.219059</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.219059</td>\n",
       "      <td>0.270998</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.084614</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.049176</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.049176</td>\n",
       "      <td>0.033451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011150</td>\n",
       "      <td>0.060784</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.022484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.057176</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.057176</td>\n",
       "      <td>0.323984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.323984</td>\n",
       "      <td>0.348378</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.120373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.073647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.073647</td>\n",
       "      <td>0.097652</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.097652</td>\n",
       "      <td>0.137354</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.056948</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.062471</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.062471</td>\n",
       "      <td>0.157836</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.157836</td>\n",
       "      <td>0.189570</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.241073</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.011059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003686</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.006409</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.401136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.401136</td>\n",
       "      <td>0.429738</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.077137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.087294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087294</td>\n",
       "      <td>0.015514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005171</td>\n",
       "      <td>0.065169</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.008844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002539</td>\n",
       "      <td>0.007421</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.080588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.080588</td>\n",
       "      <td>0.219960</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.219960</td>\n",
       "      <td>0.260474</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.040286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.006949</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.028235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028235</td>\n",
       "      <td>0.115174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.115174</td>\n",
       "      <td>0.128382</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.020007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.157063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>0.011873</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006856</td>\n",
       "      <td>0.020036</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.004706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.005937</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.012471</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.008314</td>\n",
       "      <td>0.011081</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.007387</td>\n",
       "      <td>0.017945</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.018407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.003647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.009882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.005937</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.006302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>0.008770</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.005765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.007016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.009882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>0.004502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.010052</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.006941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003980</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.009412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.009242</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.004235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.003740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.005176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001725</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.003463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.006814</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>0.008096</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.005529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.002824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>0.926207</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>626 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SECTOR_SCORE  LOCATION_ID    PARA_A  SCORE_A    RISK_A    PARA_B  \\\n",
       "0        0.035172     0.478261  0.049176      1.0  0.049176  0.017314   \n",
       "1        0.035172     0.108696  0.000000      0.0  0.000000  0.033451   \n",
       "2        0.035172     0.108696  0.006000      0.0  0.002000  0.001593   \n",
       "3        0.035172     0.108696  0.000000      0.0  0.000000  0.074797   \n",
       "4        0.035172     0.108696  0.000000      0.0  0.000000  0.000554   \n",
       "5        0.035172     0.108696  0.000000      0.0  0.000000  0.005748   \n",
       "6        0.035172     0.130435  0.012941      0.5  0.008627  0.051319   \n",
       "7        0.035172     0.152174  0.100000      1.0  0.100000  0.083316   \n",
       "8        0.035172     0.152174  0.098824      1.0  0.098824  0.076529   \n",
       "9        0.035172     0.152174  0.063882      1.0  0.063882  0.074590   \n",
       "10       0.035172     0.152174  0.180941      1.0  0.180941  0.277997   \n",
       "11       0.035172     0.152174  0.064353      1.0  0.064353  0.052843   \n",
       "12       0.035172     0.152174  0.000000      0.0  0.000000  0.005818   \n",
       "13       0.035172     0.260870  0.022941      0.5  0.015294  0.062400   \n",
       "14       0.035172     0.782609  0.100471      1.0  0.100471  0.219059   \n",
       "15       0.035172     0.782609  0.049176      1.0  0.049176  0.033451   \n",
       "16       0.035172     0.782609  0.057176      1.0  0.057176  0.323984   \n",
       "17       0.035172     0.500000  0.073647      1.0  0.073647  0.097652   \n",
       "18       0.035172     0.043478  0.062471      1.0  0.062471  0.157836   \n",
       "19       0.035172     0.043478  0.011059      0.0  0.003686  0.000069   \n",
       "20       0.035172     0.065217  0.068000      1.0  0.068000  0.401136   \n",
       "21       0.035172     0.065217  0.087294      1.0  0.087294  0.015514   \n",
       "22       0.035172     0.065217  0.000000      0.0  0.000000  0.007618   \n",
       "23       0.035172     0.282609  0.080588      1.0  0.080588  0.219960   \n",
       "24       0.035172     0.282609  0.000000      0.0  0.000000  0.007133   \n",
       "25       0.035172     0.782609  0.028235      1.0  0.028235  0.115174   \n",
       "26       0.035172     0.086957  0.000000      0.0  0.000000  0.000346   \n",
       "27       0.035172     0.086957  0.000000      0.0  0.000000  0.012189   \n",
       "28       0.035172     0.086957  0.000000      0.0  0.000000  0.020569   \n",
       "29       0.035172     0.086957  0.000000      0.0  0.000000  0.002978   \n",
       "..            ...          ...       ...      ...       ...       ...   \n",
       "599      0.926207     0.326087  0.002353      0.0  0.000784  0.000000   \n",
       "600      0.926207     0.304348  0.004706      0.0  0.001569  0.000017   \n",
       "601      0.926207     0.304348  0.000000      0.0  0.000000  0.006095   \n",
       "602      0.926207     0.304348  0.000000      0.0  0.000000  0.000000   \n",
       "603      0.926207     0.304348  0.000000      0.0  0.000000  0.000000   \n",
       "604      0.926207     0.304348  0.000000      0.0  0.000000  0.000000   \n",
       "605      0.926207     0.304348  0.000000      0.0  0.000000  0.000000   \n",
       "606      0.926207     0.260870  0.001176      0.0  0.000392  0.000000   \n",
       "607      0.926207     0.260870  0.012471      0.5  0.008314  0.011081   \n",
       "608      0.926207     0.260870  0.002941      0.0  0.000980  0.000012   \n",
       "609      0.926207     0.260870  0.003647      0.0  0.001216  0.000010   \n",
       "610      0.926207     0.260870  0.000000      0.0  0.000000  0.000000   \n",
       "611      0.926207     0.260870  0.009882      0.0  0.003294  0.000000   \n",
       "612      0.926207     0.260870  0.006000      0.0  0.002000  0.002563   \n",
       "613      0.926207     0.434783  0.001059      0.0  0.000353  0.000000   \n",
       "614      0.926207     0.369565  0.004588      0.0  0.001529  0.006302   \n",
       "615      0.926207     0.521739  0.000000      0.0  0.000000  0.000000   \n",
       "616      0.926207     0.456522  0.005765      0.0  0.001922  0.003809   \n",
       "617      0.926207     0.282609  0.009882      0.0  0.003294  0.004502   \n",
       "618      0.926207     0.282609  0.006941      0.0  0.002314  0.000000   \n",
       "619      0.926207     0.760870  0.000235      0.0  0.000078  0.000000   \n",
       "620      0.926207     0.152174  0.009412      0.0  0.003137  0.003948   \n",
       "621      0.926207     0.369565  0.004235      0.0  0.001412  0.003740   \n",
       "622      0.926207     0.173913  0.005176      0.0  0.001725  0.003671   \n",
       "623      0.926207     0.326087  0.006000      0.0  0.002000  0.003463   \n",
       "624      0.926207     0.369565  0.008824      0.0  0.002941  0.003117   \n",
       "625      0.926207     0.326087  0.005529      0.0  0.001843  0.002563   \n",
       "626      0.926207     0.282609  0.002824      0.0  0.000941  0.000277   \n",
       "627      0.926207     0.369565  0.002353      0.0  0.000784  0.000000   \n",
       "628      0.926207     0.304348  0.000000      0.0  0.000000  0.000000   \n",
       "\n",
       "     SCORE_B    RISK_B     TOTAL  NUMBERS  ...   HISTORY  PROB    RISK_F  \\\n",
       "0        0.0  0.005771  0.045065    0.000  ...  0.000000   0.0  0.000000   \n",
       "1        0.0  0.011150  0.032584    0.000  ...  0.000000   0.0  0.000000   \n",
       "2        0.0  0.000531  0.004992    0.000  ...  0.000000   0.0  0.000000   \n",
       "3        1.0  0.074797  0.072860    0.250  ...  0.000000   0.0  0.000000   \n",
       "4        0.0  0.000185  0.000540    0.000  ...  0.000000   0.0  0.000000   \n",
       "5        0.0  0.001916  0.005599    0.000  ...  0.000000   0.0  0.000000   \n",
       "6        0.5  0.034213  0.057411    0.000  ...  0.000000   0.0  0.000000   \n",
       "7        1.0  0.083316  0.138501    0.125  ...  0.000000   0.0  0.000000   \n",
       "8        1.0  0.076529  0.131215    0.125  ...  0.000000   0.0  0.000000   \n",
       "9        1.0  0.074590  0.109290    0.000  ...  0.000000   0.0  0.000000   \n",
       "10       1.0  0.277997  0.374553    0.000  ...  0.111111   0.5  0.074074   \n",
       "11       0.5  0.035229  0.088376    0.000  ...  0.111111   0.5  0.074074   \n",
       "12       0.0  0.001939  0.005667    0.000  ...  0.000000   0.0  0.000000   \n",
       "13       0.5  0.041600  0.073939    0.000  ...  0.000000   0.0  0.000000   \n",
       "14       1.0  0.219059  0.270998    0.000  ...  0.111111   0.5  0.074074   \n",
       "15       0.0  0.011150  0.060784    0.125  ...  0.000000   0.0  0.000000   \n",
       "16       1.0  0.323984  0.348378    0.125  ...  0.000000   0.0  0.000000   \n",
       "17       1.0  0.097652  0.137354    0.000  ...  0.111111   0.5  0.074074   \n",
       "18       1.0  0.157836  0.189570    0.000  ...  0.111111   0.5  0.074074   \n",
       "19       0.0  0.000023  0.006409    0.000  ...  0.000000   0.0  0.000000   \n",
       "20       1.0  0.401136  0.429738    0.000  ...  0.000000   0.0  0.000000   \n",
       "21       0.0  0.005171  0.065169    0.000  ...  0.000000   0.0  0.000000   \n",
       "22       0.0  0.002539  0.007421    0.000  ...  0.000000   0.0  0.000000   \n",
       "23       1.0  0.219960  0.260474    0.000  ...  0.000000   0.0  0.000000   \n",
       "24       0.0  0.002378  0.006949    0.000  ...  0.000000   0.0  0.000000   \n",
       "25       1.0  0.115174  0.128382    0.000  ...  0.000000   0.0  0.000000   \n",
       "26       0.0  0.000115  0.000337    0.000  ...  0.000000   0.0  0.000000   \n",
       "27       0.0  0.004063  0.011873    0.000  ...  0.000000   0.0  0.000000   \n",
       "28       0.0  0.006856  0.020036    0.000  ...  0.000000   0.0  0.000000   \n",
       "29       0.0  0.000993  0.002901    0.000  ...  0.000000   0.0  0.000000   \n",
       "..       ...       ...       ...      ...  ...       ...   ...       ...   \n",
       "599      0.0  0.000000  0.001349    0.000  ...  0.000000   0.0  0.000000   \n",
       "600      0.0  0.000006  0.002715    0.000  ...  0.000000   0.0  0.000000   \n",
       "601      0.0  0.002032  0.005937    0.000  ...  0.000000   0.0  0.000000   \n",
       "602      0.0  0.000000  0.000000    0.000  ...  0.000000   0.0  0.000000   \n",
       "603      0.0  0.000000  0.000000    0.000  ...  0.000000   0.0  0.000000   \n",
       "604      0.0  0.000000  0.000000    0.000  ...  0.000000   0.0  0.000000   \n",
       "605      0.0  0.000000  0.000000    0.000  ...  0.000000   0.0  0.000000   \n",
       "606      0.0  0.000000  0.000675    0.000  ...  0.000000   0.0  0.000000   \n",
       "607      0.5  0.007387  0.017945    0.000  ...  0.000000   0.0  0.000000   \n",
       "608      0.0  0.000004  0.001698    0.000  ...  0.000000   0.0  0.000000   \n",
       "609      0.0  0.000003  0.002101    0.000  ...  0.000000   0.0  0.000000   \n",
       "610      0.0  0.000000  0.000000    0.000  ...  0.000000   0.0  0.000000   \n",
       "611      0.0  0.000000  0.005667    0.000  ...  0.000000   0.0  0.000000   \n",
       "612      0.0  0.000854  0.005937    0.000  ...  0.000000   0.0  0.000000   \n",
       "613      0.0  0.000000  0.000607    0.000  ...  0.000000   0.0  0.000000   \n",
       "614      0.0  0.002101  0.008770    0.000  ...  0.000000   0.0  0.000000   \n",
       "615      0.0  0.000000  0.000000    0.000  ...  0.000000   0.0  0.000000   \n",
       "616      0.0  0.001270  0.007016    0.000  ...  0.000000   0.0  0.000000   \n",
       "617      0.0  0.001501  0.010052    0.000  ...  0.000000   0.0  0.000000   \n",
       "618      0.0  0.000000  0.003980    0.000  ...  0.000000   0.0  0.000000   \n",
       "619      0.0  0.000000  0.000135    0.000  ...  0.000000   0.0  0.000000   \n",
       "620      0.0  0.001316  0.009242    0.000  ...  0.000000   0.0  0.000000   \n",
       "621      0.0  0.001247  0.006072    0.000  ...  0.000000   0.0  0.000000   \n",
       "622      0.0  0.001224  0.006544    0.000  ...  0.000000   0.0  0.000000   \n",
       "623      0.0  0.001154  0.006814    0.000  ...  0.000000   0.0  0.000000   \n",
       "624      0.0  0.001039  0.008096    0.000  ...  0.000000   0.0  0.000000   \n",
       "625      0.0  0.000854  0.005667    0.000  ...  0.000000   0.0  0.000000   \n",
       "626      0.0  0.000092  0.001889    0.000  ...  0.000000   0.0  0.000000   \n",
       "627      0.0  0.000000  0.001349    0.000  ...  0.000000   0.0  0.000000   \n",
       "628      0.0  0.000000  0.000000    0.000  ...  0.000000   0.0  0.000000   \n",
       "\n",
       "      SCORE  INHERENT_RISK  CONTROL_RISK  MARKS  LOSS  LOSS_SCORE  \\\n",
       "0    0.1250       0.012320      0.000000    0.0   0.0         0.0   \n",
       "1    0.0000       0.001982      0.000000    0.0   0.0         0.0   \n",
       "2    0.0000       0.000254      0.000000    0.0   0.0         0.0   \n",
       "3    0.7500       0.027701      0.000000    1.0   0.0         0.0   \n",
       "4    0.0000       0.000027      0.000000    0.0   0.0         0.0   \n",
       "5    0.0000       0.001298      0.000000    0.0   0.0         0.0   \n",
       "6    0.3750       0.052163      0.000000    0.0   0.0         0.0   \n",
       "7    0.6875       0.028567      0.000000    0.5   0.0         0.0   \n",
       "8    0.6875       0.027145      0.000000    0.5   0.0         0.0   \n",
       "9    0.5000       0.018211      0.000000    0.0   0.0         0.0   \n",
       "10   0.6250       0.058912      0.148148    0.0   0.5         0.5   \n",
       "11   0.5000       0.022312      0.074074    0.0   0.0         0.0   \n",
       "12   0.0000       0.000291      0.000000    0.0   0.0         0.0   \n",
       "13   0.3125       0.013711      0.000000    0.0   0.0         0.0   \n",
       "14   0.6875       0.084614      0.074074    0.0   0.0         0.0   \n",
       "15   0.3750       0.022484      0.000000    0.5   0.0         0.0   \n",
       "16   0.7500       0.120373      0.000000    0.5   0.0         0.0   \n",
       "17   0.6875       0.056948      0.074074    0.0   0.0         0.0   \n",
       "18   0.6875       0.241073      0.074074    0.0   0.0         0.0   \n",
       "19   0.0000       0.000361      0.000000    0.0   0.0         0.0   \n",
       "20   0.6250       0.077137      0.000000    0.0   0.0         0.0   \n",
       "21   0.1250       0.008844      0.000000    0.0   0.0         0.0   \n",
       "22   0.0000       0.000380      0.000000    0.0   0.0         0.0   \n",
       "23   0.5000       0.040286      0.000000    0.0   0.0         0.0   \n",
       "24   0.0000       0.000354      0.000000    0.0   0.0         0.0   \n",
       "25   0.5000       0.020007      0.000000    0.0   0.0         0.0   \n",
       "26   0.1250       0.157063      0.000000    0.0   0.0         0.0   \n",
       "27   0.0000       0.000975      0.000000    0.0   0.0         0.0   \n",
       "28   0.0000       0.001996      0.000000    0.0   0.0         0.0   \n",
       "29   0.0000       0.000148      0.000000    0.0   0.0         0.0   \n",
       "..      ...            ...           ...    ...   ...         ...   \n",
       "599  0.0000       0.000069      0.000000    0.0   0.0         0.0   \n",
       "600  0.0000       0.000138      0.000000    0.0   0.0         0.0   \n",
       "601  0.0000       0.000326      0.000000    0.0   0.0         0.0   \n",
       "602  0.0000       0.000000      0.000000    0.0   0.0         0.0   \n",
       "603  0.0000       0.000000      0.000000    0.0   0.0         0.0   \n",
       "604  0.0000       0.000000      0.000000    0.0   0.0         0.0   \n",
       "605  0.0000       0.000000      0.000000    0.0   0.0         0.0   \n",
       "606  0.0000       0.000034      0.000000    0.0   0.0         0.0   \n",
       "607  0.3750       0.018407      0.000000    0.0   0.0         0.0   \n",
       "608  0.0000       0.000086      0.000000    0.0   0.0         0.0   \n",
       "609  0.0000       0.000107      0.000000    0.0   0.0         0.0   \n",
       "610  0.0000       0.000000      0.000000    0.0   0.0         0.0   \n",
       "611  0.0000       0.000289      0.000000    0.0   0.0         0.0   \n",
       "612  0.0000       0.000302      0.000000    0.0   0.0         0.0   \n",
       "613  0.0000       0.000031      0.000000    0.0   0.0         0.0   \n",
       "614  0.0000       0.000447      0.000000    0.0   0.0         0.0   \n",
       "615  0.0000       0.000000      0.000000    0.0   0.0         0.0   \n",
       "616  0.0000       0.000357      0.000000    0.0   0.0         0.0   \n",
       "617  0.0000       0.000512      0.000000    0.0   0.0         0.0   \n",
       "618  0.0000       0.000203      0.000000    0.0   0.0         0.0   \n",
       "619  0.0000       0.000007      0.000000    0.0   0.0         0.0   \n",
       "620  0.0000       0.000471      0.000000    0.0   0.0         0.0   \n",
       "621  0.0000       0.000381      0.000000    0.0   0.0         0.0   \n",
       "622  0.0000       0.000333      0.000000    0.0   0.0         0.0   \n",
       "623  0.0000       0.000378      0.000000    0.0   0.0         0.0   \n",
       "624  0.0000       0.000412      0.000000    0.0   0.0         0.0   \n",
       "625  0.0000       0.000289      0.000000    0.0   0.0         0.0   \n",
       "626  0.0000       0.000096      0.000000    0.0   0.0         0.0   \n",
       "627  0.0000       0.000069      0.000000    0.0   0.0         0.0   \n",
       "628  0.0000       0.000110      0.000000    0.0   0.0         0.0   \n",
       "\n",
       "     HISTORY_SCORE  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "5              0.0  \n",
       "6              0.0  \n",
       "7              0.0  \n",
       "8              0.0  \n",
       "9              0.0  \n",
       "10             0.5  \n",
       "11             0.5  \n",
       "12             0.0  \n",
       "13             0.0  \n",
       "14             0.5  \n",
       "15             0.0  \n",
       "16             0.0  \n",
       "17             0.5  \n",
       "18             0.5  \n",
       "19             0.0  \n",
       "20             0.0  \n",
       "21             0.0  \n",
       "22             0.0  \n",
       "23             0.0  \n",
       "24             0.0  \n",
       "25             0.0  \n",
       "26             0.0  \n",
       "27             0.0  \n",
       "28             0.0  \n",
       "29             0.0  \n",
       "..             ...  \n",
       "599            0.0  \n",
       "600            0.0  \n",
       "601            0.0  \n",
       "602            0.0  \n",
       "603            0.0  \n",
       "604            0.0  \n",
       "605            0.0  \n",
       "606            0.0  \n",
       "607            0.0  \n",
       "608            0.0  \n",
       "609            0.0  \n",
       "610            0.0  \n",
       "611            0.0  \n",
       "612            0.0  \n",
       "613            0.0  \n",
       "614            0.0  \n",
       "615            0.0  \n",
       "616            0.0  \n",
       "617            0.0  \n",
       "618            0.0  \n",
       "619            0.0  \n",
       "620            0.0  \n",
       "621            0.0  \n",
       "622            0.0  \n",
       "623            0.0  \n",
       "624            0.0  \n",
       "625            0.0  \n",
       "626            0.0  \n",
       "627            0.0  \n",
       "628            0.0  \n",
       "\n",
       "[626 rows x 28 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOFT VOTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 351   size of validation set: 118   size of test set: 157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# split data into train+validation set and test set\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# split train+validation set into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_trainval, y_trainval, random_state=1)\n",
    "\n",
    "print(\"Size of training set: {}   size of validation set: {}   size of test set:\"\n",
    "      \" {}\\n\".format(X_train.shape[0], X_valid.shape[0], X_test.shape[0]))\n",
    "\n",
    "best_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 1.0\n",
      "KNeighborsClassifier 1.0\n",
      "VotingClassifier 1.0\n",
      "LogisticRegression 1.0\n",
      "KNeighborsClassifier 1.0\n",
      "VotingClassifier 1.0\n",
      "LogisticRegression 1.0\n",
      "KNeighborsClassifier 1.0\n",
      "VotingClassifier 1.0\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression(penalty = 'l1', C = 1)\n",
    "log_clf.fit(X_trainval, y_trainval)\n",
    "knn_clf = KNeighborsClassifier(3)\n",
    "knn_clf.fit(X_trainval, y_trainval)\n",
    "\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('knn', knn_clf)], voting='soft') # list of all based models in the form a tuple\n",
    "voting_clf.fit(X_trainval, y_trainval) # to find majority voting\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, knn_clf, voting_clf):\n",
    "    clf.fit(X_trainval, y_trainval)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "from sklearn.metrics import precision_score\n",
    "for clf in (log_clf, knn_clf, voting_clf):\n",
    "    clf.fit(X_trainval, y_trainval)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, precision_score(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "    \n",
    "from sklearn.metrics import recall_score\n",
    "for clf in (log_clf, knn_clf, voting_clf):\n",
    "    clf.fit(X_trainval, y_trainval)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9957356076759062\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(penalty = 'l1', C = 1)\n",
    "log_reg.fit(X_trainval, y_trainval)\n",
    "\n",
    "print(log_reg.score(X_trainval, y_trainval))\n",
    "print(log_reg.score(X_test, y_test))\n",
    "\n",
    "\n",
    "logreg_tr_pred = log_reg.predict(X_trainval)\n",
    "logreg_test_pred = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HARD VOTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC 1.0\n",
      "KNeighborsClassifier 1.0\n",
      "VotingClassifier 1.0\n",
      "SVC 1.0\n",
      "KNeighborsClassifier 1.0\n",
      "VotingClassifier 1.0\n",
      "SVC 1.0\n",
      "KNeighborsClassifier 1.0\n",
      "VotingClassifier 1.0\n"
     ]
    }
   ],
   "source": [
    "svc_clf = SVC(C=1.0, gamma='auto')\n",
    "log_clf.fit(X_trainval, y_trainval)\n",
    "knn_clf = KNeighborsClassifier(3)\n",
    "knn_clf.fit(X_trainval, y_trainval)\n",
    "\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('svc', svc_clf), ('knn', knn_clf)], voting='hard') # list of all based models in the form a tuple\n",
    "voting_clf.fit(X_trainval, y_trainval) # to find majority voting\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (svc_clf, knn_clf, voting_clf):\n",
    "    clf.fit(X_trainval, y_trainval)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "from sklearn.metrics import precision_score\n",
    "for clf in (svc_clf, knn_clf, voting_clf):\n",
    "    clf.fit(X_trainval, y_trainval)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, precision_score(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "    \n",
    "from sklearn.metrics import recall_score\n",
    "for clf in (svc_clf, knn_clf, voting_clf):\n",
    "    clf.fit(X_trainval, y_trainval)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAGGING - LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on validation set: 0.00\n",
      "Best parameters: {'max_samples': 170, 'n_estimators': 400}\n",
      "Best cross-validation score: 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(penalty = 'l1', C = 1)\n",
    "n_estimators_vals = [100, 200, 300, 400, 500]\n",
    "max_samples_vals = [10, 50, 70, 100, 120, 150, 170, 200]\n",
    "\n",
    "\n",
    "param_grid = dict(n_estimators=n_estimators_vals, max_samples = max_samples_vals)\n",
    "\n",
    "log_bag = BaggingClassifier(log_reg,bootstrap = True, random_state=0)\n",
    "\n",
    "grid_search = GridSearchCV(log_bag, param_grid = dict(n_estimators=n_estimators_vals, max_samples = max_samples_vals), cv=10, return_train_score=True)\n",
    "grid_search.fit(X_trainval, y_trainval)\n",
    "\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(penalty = 'l1', C = 1)\n",
    "bag_clf = BaggingClassifier(log_reg, n_estimators=400, max_samples=170, bootstrap=True, random_state=0)\n",
    "\n",
    "bag_clf.fit(X_trainval, y_trainval)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9872611464968153\n",
      "1.0\n",
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(precision_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.99\n",
      "Test score: 0.99\n"
     ]
    }
   ],
   "source": [
    "bag_clf.fit(X_trainval, y_trainval)\n",
    "print('Train score: {:.2f}'.format(bag_clf.score(X_trainval, y_trainval)))\n",
    "print('Test score: {:.2f}'.format(bag_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(penalty = 'l1', C = 1)\n",
    "log_reg.fit(X_trainval, y_trainval)\n",
    "y_pred_tree = log_reg.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_tree))\n",
    "\n",
    "print(precision_score(y_test, y_pred_tree))\n",
    "\n",
    "print(recall_score(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0    1\n",
       "RISK           \n",
       "0      241    0\n",
       "1        2  226"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_trainval, logreg_tr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9957356076759062\n"
     ]
    }
   ],
   "source": [
    "print(log_reg.score(X_trainval, y_trainval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   0   1\n",
       "RISK         \n",
       "0      81   0\n",
       "1       0  76"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, logreg_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(log_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        76\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       157\n",
      "   macro avg       1.00      1.00      1.00       157\n",
      "weighted avg       1.00      1.00      1.00       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, logreg_test_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 1.000\n",
      "[1.99999996 0.99999996 0.9999999  0.99999725 0.99999723 0.99999716\n",
      " 0.99999687 0.99999682 0.99999677 0.99996298 0.99995922 0.99995718\n",
      " 0.99995614 0.99994919 0.99994846 0.9982855  0.99816322 0.99274926\n",
      " 0.99223491 0.88502964 0.70762461 0.04250934 0.04239167 0.04207386\n",
      " 0.04121566 0.04082524 0.02866025 0.01440958 0.01320529]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# predict probabilities\n",
    "probs = log_reg.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "print( thresholds )\n",
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "train_score_array = []\n",
    "test_score_array = []\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(3)\n",
    "knn.fit(X_train, y_train)\n",
    "train_score_array.append(knn.score(X_trainval, y_trainval))\n",
    "test_score_array.append(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on validation set: 0.00\n",
      "Best parameters: {'max_samples': 170, 'n_estimators': 100}\n",
      "Best cross-validation score: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "knn_clf = KNeighborsClassifier(3)\n",
    "n_estimators_vals = [100, 200, 300, 400, 500]\n",
    "max_samples_vals = [10, 50, 70, 100, 120, 150, 170, 200]\n",
    "\n",
    "\n",
    "param_grid = dict(n_estimators=n_estimators_vals, max_samples = max_samples_vals)\n",
    "\n",
    "knn_bag = BaggingClassifier(knn_clf,bootstrap = True, random_state=0)\n",
    "\n",
    "grid_search = GridSearchCV(knn_bag, param_grid = dict(n_estimators=n_estimators_vals, max_samples = max_samples_vals), cv=10, return_train_score=True)\n",
    "grid_search.fit(X_trainval, y_trainval)\n",
    "print(\"Best score on validation set: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "knn_clf = KNeighborsClassifier(3)\n",
    "knn_bag_clf = BaggingClassifier(knn_clf, n_estimators=100, max_samples=170, bootstrap=True, random_state=0)\n",
    "\n",
    "knn_bag_clf.fit(X_trainval, y_trainval)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9872611464968153\n",
      "1.0\n",
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "from  sklearn.metrics import precision_score\n",
    "print(precision_score(y_test, y_pred))\n",
    "\n",
    "from  sklearn.metrics import recall_score\n",
    "print(recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.99\n",
      "Test score: 0.99\n"
     ]
    }
   ],
   "source": [
    "knn_bag_clf.fit(X_trainval, y_trainval)\n",
    "print('Train score: {:.2f}'.format(bag_clf.score(X_trainval, y_trainval)))\n",
    "print('Test score: {:.2f}'.format(bag_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Train data\n",
      "Accuracy score:  0.997867803837953\n",
      "f1 score:  0.9978021978021978\n",
      "recall score:  0.9956140350877193\n",
      "precision:  1.0\n",
      "   \n",
      "Test data\n",
      "Accuracy score:  0.9936305732484076\n",
      "f1 score:  0.9933774834437086\n",
      "recall score:  0.9868421052631579\n",
      "precision:  1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "knnc_tr_pred = knn_bag_clf.predict(X_trainval)\n",
    "knnc_test_pred = knn_bag_clf.predict(X_test)\n",
    "print(knnc_tr_pred[4])\n",
    "\n",
    "print(\"Train data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_trainval, knnc_tr_pred))\n",
    "print(\"f1 score: \", f1_score(y_trainval, knnc_tr_pred))\n",
    "print(\"recall score: \", recall_score(y_trainval, knnc_tr_pred))\n",
    "print(\"precision: \", precision_score(y_trainval, knnc_tr_pred))\n",
    "print(\"   \")\n",
    "print(\"Test data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, knnc_test_pred))\n",
    "print(\"f1 score: \", f1_score(y_test, knnc_test_pred))\n",
    "print(\"recall score: \", recall_score(y_test, knnc_test_pred))\n",
    "print(\"precision: \", precision_score(y_test, knnc_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 1.000\n",
      "[2. 1. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# fit a model\n",
    "knn_clf.fit(X_trainval,y_trainval)\n",
    "# predict probabilities\n",
    "probs = knn_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "print( thresholds )\n",
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1=0.987 auc=1.000 ap=1.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# predict probabilities\n",
    "probs = bag_clf.predict_proba(X_test)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "\n",
    "# predict class values\n",
    "yhat = bag_clf.predict(X_test)\n",
    "\n",
    "# calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, probs)\n",
    "\n",
    "# calculate F1 score\n",
    "f1 = f1_score(y_test, yhat)\n",
    "\n",
    "# calculate precision-recall AUC\n",
    "auc = auc(recall, precision)\n",
    "# calculate average precision score\n",
    "ap = average_precision_score(y_test, probs)\n",
    "print('f1=%.3f auc=%.3f ap=%.3f' % (f1, auc, ap))\n",
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0.5, 0.5], linestyle='--')\n",
    "# plot the precision-recall curve for the model\n",
    "pyplot.plot(recall, precision, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASTING - SVC LINEAR KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## svc linear kernel\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on validation set: 0.00\n",
      "Best parameters: {'max_samples': 200, 'n_estimators': 100}\n",
      "Best cross-validation score: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "svc_clf = SVC(C=1.0, gamma='auto')\n",
    "n_estimators_vals = [100, 200, 300, 400, 500]\n",
    "max_samples_vals = [10, 50, 70, 100, 120, 150, 170, 200]\n",
    "\n",
    "\n",
    "param_grid = dict(n_estimators=n_estimators_vals, max_samples = max_samples_vals)\n",
    "\n",
    "svc_bag = BaggingClassifier(svc_clf,bootstrap = False, random_state=0)\n",
    "\n",
    "grid_search = GridSearchCV(svc_bag, param_grid = dict(n_estimators=n_estimators_vals, max_samples = max_samples_vals), cv=10, return_train_score=True)\n",
    "grid_search.fit(X_trainval, y_trainval)\n",
    "print(\"Best score on validation set: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "svc_clf = SVC(C=1.0, gamma='auto')\n",
    "svc_bag_clf = BaggingClassifier(svc_clf, n_estimators=100, max_samples=200, bootstrap= False, random_state=0)\n",
    "\n",
    "svc_bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9872611464968153\n",
      "1.0\n",
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "from  sklearn.metrics import precision_score\n",
    "print(precision_score(y_test, y_pred))\n",
    "\n",
    "from  sklearn.metrics import recall_score\n",
    "print(recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.99\n",
      "Test score: 0.99\n"
     ]
    }
   ],
   "source": [
    "svc_bag_clf.fit(X_trainval, y_trainval)\n",
    "print('Train score: {:.2f}'.format(bag_clf.score(X_trainval, y_trainval)))\n",
    "print('Test score: {:.2f}'.format(bag_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "Accuracy score:  0.9829424307036247\n",
      "f1 score:  0.9821428571428572\n",
      "recall score:  0.9649122807017544\n",
      "precision:  1.0\n",
      "   \n",
      "Test data\n",
      "Accuracy score:  0.9745222929936306\n",
      "f1 score:  0.972972972972973\n",
      "recall score:  0.9473684210526315\n",
      "precision:  1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svc_tr_pred = svc_bag_clf.predict(X_trainval)\n",
    "svc_test_pred = svc_bag_clf.predict(X_test)\n",
    "\n",
    "print(\"Train data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_trainval, svc_tr_pred))\n",
    "print(\"f1 score: \", f1_score(y_trainval, svc_tr_pred))\n",
    "print(\"recall score: \", recall_score(y_trainval, svc_tr_pred))\n",
    "print(\"precision: \", precision_score(y_trainval, svc_tr_pred))\n",
    "print(\"   \")\n",
    "print(\"Test data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, svc_test_pred))\n",
    "print(\"f1 score: \", f1_score(y_test, svc_test_pred))\n",
    "print(\"recall score: \", recall_score(y_test, svc_test_pred))\n",
    "print(\"precision: \", precision_score(y_test, svc_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1=0.973 auc=1.000 ap=1.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# predict probabilities\n",
    "probs = svc_bag_clf.predict_proba(X_test)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "\n",
    "# predict class values\n",
    "yhat = svc_bag_clf.predict(X_test)\n",
    "\n",
    "# calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, probs)\n",
    "\n",
    "# calculate F1 score\n",
    "f1 = f1_score(y_test, yhat)\n",
    "\n",
    "# calculate precision-recall AUC\n",
    "auc = auc(recall, precision)\n",
    "# calculate average precision score\n",
    "ap = average_precision_score(y_test, probs)\n",
    "print('f1=%.3f auc=%.3f ap=%.3f' % (f1, auc, ap))\n",
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0.5, 0.5], linestyle='--')\n",
    "# plot the precision-recall curve for the model\n",
    "pyplot.plot(recall, precision, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC - KERNEL RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on validation set: 0.00\n",
      "Best parameters: {'max_samples': 50, 'n_estimators': 100}\n",
      "Best cross-validation score: 1.00\n"
     ]
    }
   ],
   "source": [
    "## kernel rbf\n",
    "svc_rbf_clf = SVC(kernel='rbf',C=1.0, gamma=0.5)\n",
    "n_estimators_vals = [100, 200, 300, 400, 500]\n",
    "max_samples_vals = [10, 50, 70, 100, 120, 150, 170, 200]\n",
    "\n",
    "\n",
    "param_grid = dict(n_estimators=n_estimators_vals, max_samples = max_samples_vals)\n",
    "\n",
    "svc_bag_clf = BaggingClassifier(svc_rbf_clf,bootstrap = False, random_state=0)\n",
    "\n",
    "grid_search = GridSearchCV(svc_bag_clf , param_grid = dict(n_estimators=n_estimators_vals, max_samples = max_samples_vals), cv=10, return_train_score=True)\n",
    "grid_search.fit(X_trainval, y_trainval)\n",
    "print(\"Best score on validation set: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "svc_rbf_clf = SVC(kernel='rbf',C=1.0, gamma=0.5)\n",
    "svc_bag_clf = BaggingClassifier(svc_rbf_clf, n_estimators=100, max_samples=50, bootstrap= False, random_state=0)\n",
    "\n",
    "svc_bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9872611464968153\n",
      "1.0\n",
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "from  sklearn.metrics import precision_score\n",
    "print(precision_score(y_test, y_pred))\n",
    "\n",
    "from  sklearn.metrics import recall_score\n",
    "print(recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.99\n",
      "Test score: 0.99\n"
     ]
    }
   ],
   "source": [
    "svc_bag_clf.fit(X_trainval, y_trainval)\n",
    "print('Train score: {:.2f}'.format(bag_clf.score(X_trainval, y_trainval)))\n",
    "print('Test score: {:.2f}'.format(bag_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "Accuracy score:  0.997867803837953\n",
      "f1 score:  0.9978021978021978\n",
      "recall score:  0.9956140350877193\n",
      "precision:  1.0\n",
      "   \n",
      "Test data\n",
      "Accuracy score:  1.0\n",
      "f1 score:  1.0\n",
      "recall score:  1.0\n",
      "precision:  1.0\n"
     ]
    }
   ],
   "source": [
    "svc_tr_pred = svc_bag_clf.predict(X_trainval)\n",
    "svc_test_pred = svc_bag_clf.predict(X_test)\n",
    "\n",
    "print(\"Train data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_trainval, svc_tr_pred))\n",
    "print(\"f1 score: \", f1_score(y_trainval, svc_tr_pred))\n",
    "print(\"recall score: \", recall_score(y_trainval, svc_tr_pred))\n",
    "print(\"precision: \", precision_score(y_trainval, svc_tr_pred))\n",
    "print(\"   \")\n",
    "print(\"Test data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, svc_test_pred))\n",
    "print(\"f1 score: \", f1_score(y_test, svc_test_pred))\n",
    "print(\"recall score: \", recall_score(y_test, svc_test_pred))\n",
    "print(\"precision: \", precision_score(y_test, svc_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1=1.000 auc=1.000 ap=1.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# predict probabilities\n",
    "probs = svc_bag_clf.predict_proba(X_test)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "\n",
    "# predict class values\n",
    "yhat = svc_bag_clf.predict(X_test)\n",
    "\n",
    "# calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, probs)\n",
    "\n",
    "# calculate F1 score\n",
    "f1 = f1_score(y_test, yhat)\n",
    "\n",
    "# calculate precision-recall AUC\n",
    "auc = auc(recall, precision)\n",
    "# calculate average precision score\n",
    "ap = average_precision_score(y_test, probs)\n",
    "print('f1=%.3f auc=%.3f ap=%.3f' % (f1, auc, ap))\n",
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0.5, 0.5], linestyle='--')\n",
    "# plot the precision-recall curve for the model\n",
    "pyplot.plot(recall, precision, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRADIENT BOOSTING - DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier(max_depth=4)\n",
    "dt_clf.fit(X_trainval, y_trainval)\n",
    "dt_pred = dt_clf.predict(X_trainval)\n",
    "dt_test_pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbrt = GradientBoostingClassifier(random_state=0, max_depth=4)\n",
    "gbrt.fit(X_trainval, y_trainval)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_trainval, y_trainval)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=4,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=0,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbrt.fit(X_trainval, y_trainval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt_tr_pred = gbrt.predict(X_trainval)\n",
    "gbrt_test_pred = gbrt.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gbrt_tr_pred = gbrt.predict(X_trainval)\n",
    "gbrt_test_pred= gbrt.predict(X_test)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "Accuracy score:  1.0\n",
      "f1 score:  1.0\n",
      "recall score:  1.0\n",
      "precision:  1.0\n",
      "   \n",
      "Test data\n",
      "Accuracy score:  1.0\n",
      "f1 score:  1.0\n",
      "recall score:  1.0\n",
      "precision:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_trainval, dt_pred))\n",
    "print(\"f1 score: \", f1_score(y_trainval, dt_pred))\n",
    "print(\"recall score: \", recall_score(y_trainval, dt_pred))\n",
    "print(\"precision: \", precision_score(y_trainval, dt_pred))\n",
    "print(\"   \")\n",
    "print(\"Test data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, dt_test_pred))\n",
    "print(\"f1 score: \", f1_score(y_test, dt_test_pred))\n",
    "print(\"recall score: \", recall_score(y_test, dt_test_pred))\n",
    "print(\"precision: \", precision_score(y_test, dt_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADABOOST CLASSIFIER - LINEAR SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## linear svc\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lsvc = LinearSVC(C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on validation set: 0.00\n",
      "Best parameters: {'learning_rate': 0.01, 'n_estimators': 100}\n",
      "Best cross-validation score: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "lsvc = LinearSVC(C=1)\n",
    "\n",
    "n_estimators_vals = [100, 200, 300, 400, 500]\n",
    "learning_rate_vals = [0.01, 0.1, 0.3, 0.5, 1.0]\n",
    "\n",
    "\n",
    "param_grid = dict(n_estimators=n_estimators_vals, learning_rate = learning_rate_vals)\n",
    "lsvc_ada = AdaBoostClassifier(lsvc, algorithm=\"SAMME\",random_state=0)\n",
    "grid_search = GridSearchCV(lsvc_ada, param_grid = dict(n_estimators=n_estimators_vals, learning_rate = learning_rate_vals), cv=10, return_train_score=True)\n",
    "grid_search.fit(X_trainval, y_trainval)\n",
    "print(\"Best score on validation set: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(LinearSVC(C=1), n_estimators=100, algorithm=\"SAMME\", learning_rate=0.01, random_state=0)\n",
    "ada_clf.fit(X_trainval, y_trainval)\n",
    "\n",
    "\n",
    "clf_tr_pred = ada_clf.predict(X_trainval)\n",
    "clf_test_pred = ada_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "Accuracy score:  0.997867803837953\n",
      "f1 score:  0.9978021978021978\n",
      "recall score:  0.9956140350877193\n",
      "precision:  1.0\n",
      "   \n",
      "Test data\n",
      "Accuracy score:  1.0\n",
      "f1 score:  1.0\n",
      "recall score:  1.0\n",
      "precision:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_trainval, clf_tr_pred))\n",
    "print(\"f1 score: \", f1_score(y_trainval, clf_tr_pred))\n",
    "print(\"recall score: \", recall_score(y_trainval, clf_tr_pred))\n",
    "print(\"precision: \", precision_score(y_trainval, clf_tr_pred))\n",
    "print(\"   \")\n",
    "print(\"Test data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, clf_test_pred))\n",
    "print(\"f1 score: \", f1_score(y_test, clf_test_pred))\n",
    "print(\"recall score: \", recall_score(y_test, clf_test_pred))\n",
    "print(\"precision: \", precision_score(y_test, clf_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0    1\n",
       "RISK           \n",
       "0      241    0\n",
       "1        1  227"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_trainval, clf_tr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   0   1\n",
       "RISK         \n",
       "0      81   0\n",
       "1       0  76"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, clf_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        76\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       157\n",
      "   macro avg       1.00      1.00      1.00       157\n",
      "weighted avg       1.00      1.00      1.00       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, clf_test_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC KERNEL POLY- ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## svc poly\n",
    "\n",
    "poly_clf = SVC(kernel='poly',C=1.0, degree=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.5, 'n_estimators': 100}\n",
      "Best cross-validation score: 0.58\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "poly_clf = SVC(kernel='poly',C=1.0, degree=1)\n",
    "\n",
    "n_estimators_vals = [100, 200, 300, 400, 500]\n",
    "learning_rate_vals = [0.01, 0.1, 0.3, 0.5, 1.0]\n",
    "\n",
    "\n",
    "param_grid = dict(n_estimators=n_estimators_vals, learning_rate = learning_rate_vals)\n",
    "poly_clf_ada = AdaBoostClassifier(poly_clf, algorithm=\"SAMME\",random_state=0)\n",
    "grid_search = GridSearchCV(poly_clf_ada , param_grid = dict(n_estimators=n_estimators_vals, learning_rate = learning_rate_vals), cv=10, return_train_score=True)\n",
    "grid_search.fit(X_trainval, y_trainval)\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "poly_clf = SVC(kernel='poly',C=1.0, degree=1)\n",
    "poly_ada_clf = AdaBoostClassifier(poly_clf, n_estimators=100, algorithm=\"SAMME\", learning_rate=0.5, random_state=0)\n",
    "poly_ada_clf.fit(X_trainval, y_trainval)\n",
    "\n",
    "\n",
    "clf_tr_pred = poly_ada_clf.predict(X_trainval)\n",
    "clf_test_pred = poly_ada_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "Accuracy score:  0.5138592750533049\n",
      "f1 score:  0.0\n",
      "recall score:  0.0\n",
      "precision:  0.0\n",
      "   \n",
      "Test data\n",
      "Accuracy score:  0.5159235668789809\n",
      "f1 score:  0.0\n",
      "recall score:  0.0\n",
      "precision:  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_trainval, clf_tr_pred))\n",
    "print(\"f1 score: \", f1_score(y_trainval, clf_tr_pred))\n",
    "print(\"recall score: \", recall_score(y_trainval, clf_tr_pred))\n",
    "print(\"precision: \", precision_score(y_trainval, clf_tr_pred))\n",
    "print(\"   \")\n",
    "print(\"Test data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, clf_test_pred))\n",
    "print(\"f1 score: \", f1_score(y_test, clf_test_pred))\n",
    "print(\"recall score: \", recall_score(y_test, clf_test_pred))\n",
    "print(\"precision: \", precision_score(y_test, clf_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEEP NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 0s 405us/sample - loss: 0.7721 - accuracy: 0.1620\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 0s 16us/sample - loss: 0.7652 - accuracy: 0.1684\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 0s 16us/sample - loss: 0.7582 - accuracy: 0.1791\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 0s 15us/sample - loss: 0.7516 - accuracy: 0.1876\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 0s 14us/sample - loss: 0.7448 - accuracy: 0.2068\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 0s 20us/sample - loss: 0.7383 - accuracy: 0.2281\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 0s 17us/sample - loss: 0.7316 - accuracy: 0.2495\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 0s 14us/sample - loss: 0.7250 - accuracy: 0.2623\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 0s 14us/sample - loss: 0.7185 - accuracy: 0.2857\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 0s 22us/sample - loss: 0.7120 - accuracy: 0.3006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13bf3fe10>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 1: build model\n",
    "model1 = Sequential()\n",
    "#input layer\n",
    "model1.add(Dense(10, input_dim = 28, activation = 'relu'))\n",
    "#hidden layers\n",
    "#output layer\n",
    "model1.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "#step 2: make computational graph - compile\n",
    "opt = SGD(lr=0.01, momentum=0.9)\n",
    "model1.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "\n",
    "#step 3: train the model - fit\n",
    "model1.fit(X_trainval, y_trainval, epochs = 10, batch_size = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "\n",
    "pca = PCA().fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 351   size of validation set: 118   size of test set: 157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split data into train+validation set and test set\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# split data into train+validation set and test set\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# split train+validation set into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_trainval, y_trainval, random_state=1)\n",
    "\n",
    "print(\"Size of training set: {}   size of validation set: {}   size of test set:\"\n",
    "      \" {}\\n\".format(X_train.shape[0], X_valid.shape[0], X_test.shape[0]))\n",
    "\n",
    "best_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "\n",
    "X_trainval = pca.fit_transform(X_trainval)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(469, 10)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 10)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65195423, 0.1617534 , 0.13172169, 0.115613  , 0.07155135,\n",
       "       0.06024924, 0.05344001, 0.04211779, 0.03353733, 0.03023716])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47388799, 0.11757419, 0.09574495, 0.08403598, 0.05200875,\n",
       "       0.04379355, 0.03884411, 0.03061429, 0.02437738, 0.02197858])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.982859760634868"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN AFTER PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "train_score_array = []\n",
    "test_score_array = []\n",
    "\n",
    "for k in range(1,20):\n",
    "    knn = KNeighborsClassifier(k)\n",
    "    knn.fit(X_trainval, y_trainval)\n",
    "    train_score_array.append(knn.score(X_trainval, y_trainval))\n",
    "    test_score_array.append(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x13f6eec18>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = range(1,20)\n",
    "%matplotlib inline\n",
    "plt.plot(x_axis, train_score_array, label = 'Train Score', c = 'g')\n",
    "plt.plot(x_axis, test_score_array, label = 'Test Score', c='b')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_neighbors': 1, 'weights': 'uniform'}\n",
      "Best cross-validation score: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score , GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "#param_grid = dict(k_range' : [1,3,5,7,9,12,15,17,20])\n",
    "k_range = [1,3,5,7,9,12,15,17,20]          \n",
    "weights_range = ['uniform','distance'] \n",
    "param_grid = dict(n_neighbors=k_range, weights = weights_range)\n",
    "\n",
    "\n",
    "#grid_search = GridSearchCV(knn, param_grid, cv=10, return_train_score=True)\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=10, return_train_score=True)\n",
    "grid_search.fit(X_trainval, y_trainval)\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "train_score_array = []\n",
    "test_score_array = []\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(3)\n",
    "knn.fit(X_trainval, y_trainval)\n",
    "train_score_array.append(knn.score(X_trainval, y_trainval))\n",
    "test_score_array.append(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Train data\n",
      "Accuracy score:  1.0\n",
      "f1 score:  1.0\n",
      "recall score:  1.0\n",
      "precision:  1.0\n",
      "   \n",
      "Test data\n",
      "Accuracy score:  1.0\n",
      "f1 score:  1.0\n",
      "recall score:  1.0\n",
      "precision:  1.0\n"
     ]
    }
   ],
   "source": [
    "knn_c_bst_clf = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn_c_bst_clf.fit(X_trainval,y_trainval)\n",
    "\n",
    "knnc_tr_pred = knn_c_bst_clf.predict(X_trainval)\n",
    "knnc_test_pred = knn_c_bst_clf.predict(X_test)\n",
    "print(knnc_tr_pred[4])\n",
    "\n",
    "print(\"Train data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_trainval, knnc_tr_pred))\n",
    "print(\"f1 score: \", f1_score(y_trainval, knnc_tr_pred))\n",
    "print(\"recall score: \", recall_score(y_trainval, knnc_tr_pred))\n",
    "print(\"precision: \", precision_score(y_trainval, knnc_tr_pred))\n",
    "print(\"   \")\n",
    "print(\"Test data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, knnc_test_pred))\n",
    "print(\"f1 score: \", f1_score(y_test, knnc_test_pred))\n",
    "print(\"recall score: \", recall_score(y_test, knnc_test_pred))\n",
    "print(\"precision: \", precision_score(y_test, knnc_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0    1\n",
       "RISK           \n",
       "0      241    0\n",
       "1        0  228"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_trainval, knnc_tr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   0   1\n",
       "RISK         \n",
       "0      81   0\n",
       "1       0  76"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, knnc_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        76\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       157\n",
      "   macro avg       1.00      1.00      1.00       157\n",
      "weighted avg       1.00      1.00      1.00       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, knnc_test_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 1.000\n",
      "[2. 1. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# fit a model\n",
    "knn_c_bst_clf.fit(X_trainval,y_trainval)\n",
    "# predict probabilities\n",
    "probs = knn_c_bst_clf.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "print( thresholds )\n",
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1=1.000 auc=1.000 ap=1.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# predict probabilities\n",
    "probs = knn_c_bst_clf.predict_proba(X_test)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "\n",
    "# predict class values\n",
    "yhat = knn_c_bst_clf.predict(X_test)\n",
    "\n",
    "# calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, probs)\n",
    "\n",
    "# calculate F1 score\n",
    "f1 = f1_score(y_test, yhat)\n",
    "\n",
    "# calculate precision-recall AUC\n",
    "auc = auc(recall, precision)\n",
    "# calculate average precision score\n",
    "ap = average_precision_score(y_test, probs)\n",
    "print('f1=%.3f auc=%.3f ap=%.3f' % (f1, auc, ap))\n",
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0.5, 0.5], linestyle='--')\n",
    "# plot the precision-recall curve for the model\n",
    "pyplot.plot(recall, precision, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "c_range = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "train_score_l1 = []\n",
    "train_score_l2 = []\n",
    "test_score_l1 = []\n",
    "test_score_l2 = []\n",
    "\n",
    "for c in c_range:\n",
    "    log_l1 = LogisticRegression(penalty = 'l1', C = c)\n",
    "    log_l2 = LogisticRegression(penalty = 'l2', C = c)\n",
    "    log_l1.fit(X_trainval, y_trainval)\n",
    "    log_l2.fit(X_trainval, y_trainval)\n",
    "    train_score_l1.append(log_l1.score(X_trainval, y_trainval))\n",
    "    train_score_l2.append(log_l2.score(X_trainval, y_trainval))\n",
    "    test_score_l1.append(log_l1.score(X_test, y_test))\n",
    "    test_score_l2.append(log_l2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(c_range, train_score_l1, label = 'Train score, penalty = l1')\n",
    "plt.plot(c_range, test_score_l1, label = 'Test score, penalty = l1')\n",
    "plt.plot(c_range, train_score_l2, label = 'Train score, penalty = l2')\n",
    "plt.plot(c_range, test_score_l2, label = 'Test score, penalty = l2')\n",
    "plt.legend()\n",
    "plt.xlabel('Regularization parameter: C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "c_range = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "penalty_mod = ['l1','l2']\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "#create a parameter grid: map the parameter names to the values that should be searched\n",
    "param_grid = dict(penalty=penalty_mod,C=c_range)\n",
    "print(param_grid)\n",
    "\n",
    "#instantiation of the grid\n",
    "log_reg_grid = GridSearchCV(log_reg,param_grid, cv=10, scoring='accuracy')\n",
    "\n",
    "# fitting the grid\n",
    "log_reg_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [1.         0.984375   1.         1.         1.         1.\n",
      " 0.98387097 1.         1.         0.83870968]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(log_reg, X, y,cv=10) # input arguments followed by X and Y\n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9936034115138592\n",
      "0.9872611464968153\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(penalty = 'l2', C = 1)\n",
    "log_reg.fit(X_trainval, y_trainval)\n",
    "\n",
    "print(log_reg.score(X_trainval, y_trainval))\n",
    "print(log_reg.score(X_test, y_test))\n",
    "\n",
    "\n",
    "logreg_tr_pred = log_reg.predict(X_trainval)\n",
    "logreg_test_pred = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0    1\n",
       "RISK           \n",
       "0      241    0\n",
       "1        3  225"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_trainval, logreg_tr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9936034115138592\n"
     ]
    }
   ],
   "source": [
    "print(log_reg.score(X_trainval, y_trainval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   0   1\n",
       "RISK         \n",
       "0      81   0\n",
       "1       2  74"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, logreg_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9872611464968153\n"
     ]
    }
   ],
   "source": [
    "print(log_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        81\n",
      "           1       1.00      0.97      0.99        76\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       157\n",
      "   macro avg       0.99      0.99      0.99       157\n",
      "weighted avg       0.99      0.99      0.99       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, logreg_test_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9936034115138592\n",
      "f1 score:  0.9933774834437086\n",
      "recall score:  0.9868421052631579\n",
      "precision:  1.0\n",
      "   \n",
      "Test data\n",
      "Accuracy score:  0.9872611464968153\n",
      "f1 score:  0.9866666666666666\n",
      "recall score:  0.9736842105263158\n",
      "precision:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy score: \", accuracy_score(y_trainval, logreg_tr_pred))\n",
    "print(\"f1 score: \", f1_score(y_trainval, logreg_tr_pred))\n",
    "print(\"recall score: \", recall_score(y_trainval, logreg_tr_pred))\n",
    "print(\"precision: \", precision_score(y_trainval, logreg_tr_pred))\n",
    "print(\"   \")\n",
    "print(\"Test data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, logreg_test_pred))\n",
    "print(\"f1 score: \", f1_score(y_test, logreg_test_pred))\n",
    "print(\"recall score: \", recall_score(y_test, logreg_test_pred))\n",
    "print(\"precision: \", precision_score(y_test, logreg_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 1.000\n",
      "[1.99999316 0.99999316 0.35667142 0.02871102 0.0286869  0.02832757\n",
      " 0.02813376 0.02696169 0.02615027 0.02493556]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# predict probabilities\n",
    "probs = log_reg.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "print( thresholds )\n",
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1=0.987 auc=1.000 ap=1.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# predict probabilities\n",
    "probs = log_reg.predict_proba(X_test)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "\n",
    "# predict class values\n",
    "y_prd_class_val = log_reg.predict(X_test)\n",
    "\n",
    "# calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, probs)\n",
    "\n",
    "# calculate F1 score\n",
    "f1 = f1_score(y_test, y_prd_class_val)\n",
    "\n",
    "# calculate precision-recall AUC\n",
    "auc = auc(recall, precision)\n",
    "# calculate average precision score\n",
    "ap = average_precision_score(y_test, probs)\n",
    "print('f1=%.3f auc=%.3f ap=%.3f' % (f1, auc, ap))\n",
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0.5, 0.5], linestyle='--')\n",
    "# plot the precision-recall curve for the model\n",
    "pyplot.plot(recall, precision, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINEAR SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter grid:\n",
      "{'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n"
     ]
    }
   ],
   "source": [
    "c_range= [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "param_grid = dict(C=c_range)\n",
    "print(\"Parameter grid:\\n{}\".format(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC()\n",
    "linearsvc_grid_search = GridSearchCV(estimator=clf, param_grid = dict(C=c_range)   ,n_jobs=-1)\n",
    "linearsvc_grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearsvc_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_best = LinearSVC(C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_best.fit(X_trainval, y_trainval)\n",
    "\n",
    "clf_tr_pred = clf_best.predict(X_trainval)\n",
    "clf_test_pred = clf_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "Accuracy score:  0.997867803837953\n",
      "f1 score:  0.9978021978021978\n",
      "recall score:  0.9956140350877193\n",
      "precision:  1.0\n",
      "   \n",
      "Test data\n",
      "Accuracy score:  1.0\n",
      "f1 score:  1.0\n",
      "recall score:  1.0\n",
      "precision:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_trainval, clf_tr_pred))\n",
    "print(\"f1 score: \", f1_score(y_trainval, clf_tr_pred))\n",
    "print(\"recall score: \", recall_score(y_trainval, clf_tr_pred))\n",
    "print(\"precision: \", precision_score(y_trainval, clf_tr_pred))\n",
    "print(\"   \")\n",
    "print(\"Test data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, clf_test_pred))\n",
    "print(\"f1 score: \", f1_score(y_test, clf_test_pred))\n",
    "print(\"recall score: \", recall_score(y_test, clf_test_pred))\n",
    "print(\"precision: \", precision_score(y_test, clf_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0    1\n",
       "RISK           \n",
       "0      241    0\n",
       "1        1  227"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_trainval, clf_tr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   0   1\n",
       "RISK         \n",
       "0      81   0\n",
       "1       0  76"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, clf_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        76\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       157\n",
      "   macro avg       1.00      1.00      1.00       157\n",
      "weighted avg       1.00      1.00      1.00       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, clf_test_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC LINEAR KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter grid:\n",
      "{'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score , GridSearchCV\n",
    "\n",
    "c_range= [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "param_grid = dict(C=c_range)\n",
    "print(\"Parameter grid:\\n{}\".format(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(kernel='linear')\n",
    "grid_search = GridSearchCV(estimator=svc, param_grid = dict(C=c_range) ,n_jobs=-1)\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9984025559105432"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_best = SVC(C=10, gamma='auto',probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_best.fit(X_trainval, y_trainval)\n",
    "\n",
    "svc_tr_pred = svc_best.predict(X_trainval)\n",
    "svc_test_pred = svc_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "Accuracy score:  0.997867803837953\n",
      "f1 score:  0.9978021978021978\n",
      "recall score:  0.9956140350877193\n",
      "precision:  1.0\n",
      "   \n",
      "Test data\n",
      "Accuracy score:  1.0\n",
      "f1 score:  1.0\n",
      "recall score:  1.0\n",
      "precision:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_trainval, svc_tr_pred))\n",
    "print(\"f1 score: \", f1_score(y_trainval, svc_tr_pred))\n",
    "print(\"recall score: \", recall_score(y_trainval, svc_tr_pred))\n",
    "print(\"precision: \", precision_score(y_trainval, svc_tr_pred))\n",
    "print(\"   \")\n",
    "print(\"Test data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, svc_test_pred))\n",
    "print(\"f1 score: \", f1_score(y_test, svc_test_pred))\n",
    "print(\"recall score: \", recall_score(y_test, svc_test_pred))\n",
    "print(\"precision: \", precision_score(y_test, svc_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0    1\n",
       "RISK           \n",
       "0      241    0\n",
       "1        1  227"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_trainval, svc_tr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   0   1\n",
       "RISK         \n",
       "0      81   0\n",
       "1       0  76"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, svc_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        76\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       157\n",
      "   macro avg       1.00      1.00      1.00       157\n",
      "weighted avg       1.00      1.00      1.00       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, svc_test_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 1.000\n",
      "[2.         1.         0.94359095 0.01022384 0.01022288 0.00993117\n",
      " 0.00992115 0.00968229 0.00967852 0.00834227]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### ROC curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# predict probabilities\n",
    "probs = svc_best.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "print( thresholds )\n",
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC KERNEL RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter grid:\n",
      "{'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': [0.001, 0.05, 0.07, 0.03, 0.01, 0.5, 0.3, 0.1, 1, 10, 100]}\n"
     ]
    }
   ],
   "source": [
    "#from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score , GridSearchCV\n",
    "\n",
    "c_range= [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "gamma_range=[0.001, 0.05,0.07,0.03,0.01,0.5,0.3, 0.1, 1, 10, 100]\n",
    "\n",
    "param_grid = dict(C=c_range, gamma=gamma_range)\n",
    "print(\"Parameter grid:\\n{}\".format(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': [0.001, 0.05, 0.07, 0.03, 0.01, 0.5, 0.3, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf')\n",
    "grid_search = GridSearchCV(estimator=svc, param_grid = dict(C=c_range,gamma=gamma_range) ,n_jobs=-1)\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9984025559105432"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'gamma': 0.5}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_best_rbf = SVC(kernel='rbf',C=1.0, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_best_rbf.fit(X_trainval, y_trainval)\n",
    "\n",
    "svc_rbf_tr_pred = svc_best_rbf.predict(X_trainval)\n",
    "svc_rbf_test_pred = svc_best_rbf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "Accuracy score:  0.997867803837953\n",
      "f1 score:  0.9978021978021978\n",
      "recall score:  0.9956140350877193\n",
      "precision:  1.0\n",
      "   \n",
      "Test data\n",
      "Accuracy score:  1.0\n",
      "f1 score:  1.0\n",
      "recall score:  1.0\n",
      "precision:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_trainval, svc_rbf_tr_pred))\n",
    "print(\"f1 score: \", f1_score(y_trainval, svc_rbf_tr_pred))\n",
    "print(\"recall score: \", recall_score(y_trainval, svc_rbf_tr_pred))\n",
    "print(\"precision: \", precision_score(y_trainval, svc_rbf_tr_pred))\n",
    "print(\"   \")\n",
    "print(\"Test data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, svc_rbf_test_pred))\n",
    "print(\"f1 score: \", f1_score(y_test, svc_rbf_test_pred))\n",
    "print(\"recall score: \", recall_score(y_test, svc_rbf_test_pred))\n",
    "print(\"precision: \", precision_score(y_test, svc_rbf_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0    1\n",
       "RISK           \n",
       "0      241    0\n",
       "1        1  227"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_trainval, svc_rbf_tr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   0   1\n",
       "RISK         \n",
       "0      81   0\n",
       "1       0  76"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, svc_rbf_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        76\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       157\n",
      "   macro avg       1.00      1.00      1.00       157\n",
      "weighted avg       1.00      1.00      1.00       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, svc_rbf_test_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC KERNEL POLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter grid:\n",
      "{'C': [0.001, 0.01, 0.1, 1, 10, 100], 'degree': [1, 2, 3, 4]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score , GridSearchCV\n",
    "\n",
    "c_range= [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "degree_range=[1,2,3,4]\n",
    "\n",
    "param_grid = dict(C=c_range, degree = degree_range)\n",
    "print(\"Parameter grid:\\n{}\".format(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='poly', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100], 'degree': [1, 2, 3, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(kernel='poly')\n",
    "grid_search = GridSearchCV(estimator=svc, param_grid = dict(C=c_range,degree = degree_range) ,n_jobs=-1)\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9984025559105432"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'degree': 1}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_best_poly = SVC(kernel='poly',C=100, degree=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_best_poly.fit(X_trainval, y_trainval)\n",
    "\n",
    "svc_poly_tr_pred = svc_best_poly.predict(X_trainval)\n",
    "svc_poly_test_pred = svc_best_poly.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "Accuracy score:  1.0\n",
      "f1 score:  1.0\n",
      "recall score:  1.0\n",
      "precision:  1.0\n",
      "   \n",
      "Test data\n",
      "Accuracy score:  1.0\n",
      "f1 score:  1.0\n",
      "recall score:  1.0\n",
      "precision:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_trainval, svc_poly_tr_pred))\n",
    "print(\"f1 score: \", f1_score(y_trainval, svc_poly_tr_pred))\n",
    "print(\"recall score: \", recall_score(y_trainval, svc_poly_tr_pred))\n",
    "print(\"precision: \", precision_score(y_trainval, svc_poly_tr_pred))\n",
    "print(\"   \")\n",
    "print(\"Test data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, svc_poly_test_pred))\n",
    "print(\"f1 score: \", f1_score(y_test, svc_poly_test_pred))\n",
    "print(\"recall score: \", recall_score(y_test, svc_poly_test_pred))\n",
    "print(\"precision: \", precision_score(y_test, svc_poly_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0    1\n",
       "RISK           \n",
       "0      241    0\n",
       "1        0  228"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_trainval, svc_poly_tr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   0   1\n",
       "RISK         \n",
       "0      81   0\n",
       "1       0  76"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, svc_rbf_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        76\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       157\n",
      "   macro avg       1.00      1.00      1.00       157\n",
      "weighted avg       1.00      1.00      1.00       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, svc_poly_test_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_depth': [4, 6, 8, 10]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring='accuracy',\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "param_grid = dict(max_depth=[4,6,8,10])\n",
    "\n",
    "gs_dt = GridSearchCV(dt, param_grid=param_grid, cv=10, scoring='accuracy')\n",
    "gs_dt.fit(X_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_best = DecisionTreeClassifier(max_depth=4)\n",
    "dt_best.fit(X_trainval, y_trainval)\n",
    "dt_pred = dt_best.predict(X_trainval)\n",
    "dt_test_pred = dt_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "Accuracy score:  1.0\n",
      "f1 score:  1.0\n",
      "recall score:  1.0\n",
      "precision:  1.0\n",
      "   \n",
      "Test data\n",
      "Accuracy score:  1.0\n",
      "f1 score:  1.0\n",
      "recall score:  1.0\n",
      "precision:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_trainval, dt_pred))\n",
    "print(\"f1 score: \", f1_score(y_trainval, dt_pred))\n",
    "print(\"recall score: \", recall_score(y_trainval, dt_pred))\n",
    "print(\"precision: \", precision_score(y_trainval, dt_pred))\n",
    "print(\"   \")\n",
    "print(\"Test data\")\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, dt_test_pred))\n",
    "print(\"f1 score: \", f1_score(y_test, dt_test_pred))\n",
    "print(\"recall score: \", recall_score(y_test, dt_test_pred))\n",
    "print(\"precision: \", precision_score(y_test, dt_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0    1\n",
       "RISK           \n",
       "0      241    0\n",
       "1        0  228"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_trainval, dt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   0   1\n",
       "RISK         \n",
       "0      81   0\n",
       "1       0  76"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, dt_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        76\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       157\n",
      "   macro avg       1.00      1.00      1.00       157\n",
      "weighted avg       1.00      1.00      1.00       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, dt_test_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 1.000\n",
      "[2. 1. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### ROC curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# predict probabilities\n",
    "probs = dt_best.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "print( thresholds )\n",
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1=1.000 auc=1.000 ap=1.000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAD+9JREFUeJzt3X+QXXV5x/H3x8SIWvmhWR0gkYAN1ai0wE7UsSot2gamJlO0GmawYimptuDU/oTaUZpO67RTa8dOqsYOojgS0HGcpaUyFXCgDEg25YckFAwRTICRRSBOVQyBp3/cS91sQu7d5O5u9pv3a+ZO7jnfZ+55vnvvfvbcc+7NSVUhSWrLc2a6AUnS4BnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAbNnakNz58/vxYtWjRTm5ekWWnDhg2PVNVQr7oZC/dFixYxOjo6U5uXpFkpyf391HlYRpIaZLhLUoMMd0lqkOEuSQ0y3CWpQT3DPcnFSR5OcuezjCfJJ5NsTnJHkpMG36YkaTL62XO/BFi2l/HTgMXd2yrgU/vf1l5svQVu+HjnX0mabaYpw3p+zr2qrk+yaC8lK4AvVOd6fTcnOTzJkVX10IB6/Jmtt8DnToOnd0KeAy97DTzv0IFvRpKmxE9/CN+/E6pg7iHw3hFYuHRKNjWIY+5HA1vHLW/rrttNklVJRpOMjo2NTX5L990ATz/VuV9PwxPbJ/8YkjRTntjeyS4KntrRybQpMq3fUK2qtcBagOHh4clfmXvRmzp/7Z7aAXPmwTv+dcr+6knSwG29BT6//GcZtuhNU7apQYT7A8DCccsLuusGb+HSztuY+27o/FAMdkmzyTRm2CDCfQQ4L8k64HXA9ik53v6MhUsNdUmz1zRlWM9wT3IZcAowP8k24KPAcwGq6tPAVcDpwGbgx8D7pqpZSVJ/+vm0zJk9xgv4g4F1JEnab35DVZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDWor3BPsizJ3Uk2J7lgD+PHJLkmyR1JvplkweBblST1q2e4J5kDrAFOA5YAZyZZMqHsH4AvVNUJwGrgY4NuVJLUv3723JcCm6tqS1XtANYBKybULAGu7d6/bg/jkqRp1E+4Hw1sHbe8rbtuvNuBM7r3fxN4UZKX7H97kqR9MagTqn8CvCXJrcBbgAeApyYWJVmVZDTJ6NjY2IA2LUmaqJ9wfwBYOG55QXfd/6uqB6vqjKo6Efhwd93jEx+oqtZW1XBVDQ8NDe1H25Kkvekn3NcDi5Mcm2QesBIYGV+QZH6SZx7rQuDiwbYpSZqMnuFeVTuB84CrgbuAK6pqY5LVSZZ3y04B7k5yD/Ay4G+mqF9JUh9SVTOy4eHh4RodHZ2RbUvSbJVkQ1UN96rzG6qS1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDWor3BPsizJ3Uk2J7lgD+MvT3JdkluT3JHk9MG3KknqV89wTzIHWAOcBiwBzkyyZELZXwJXVNWJwErgXwbdqCSpf/3suS8FNlfVlqraAawDVkyoKeDQ7v3DgAcH16IkabL6Cfejga3jlrd11413EXBWkm3AVcD5e3qgJKuSjCYZHRsb24d2JUn9GNQJ1TOBS6pqAXA6cGmS3R67qtZW1XBVDQ8NDQ1o05KkifoJ9weAheOWF3TXjXcOcAVAVd0EHALMH0SDkqTJ6yfc1wOLkxybZB6dE6YjE2q+B5wKkORVdMLd4y6SNEN6hntV7QTOA64G7qLzqZiNSVYnWd4t+2Pg3CS3A5cBZ1dVTVXTkqS9m9tPUVVdRedE6fh1Hxl3fxPwxsG2JknaV35DVZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDWor3BPsizJ3Uk2J7lgD+OfSHJb93ZPkscH36okqV9zexUkmQOsAd4GbAPWJxmpqk3P1FTVh8bVnw+cOAW9SpL61M+e+1Jgc1VtqaodwDpgxV7qzwQuG0RzkqR900+4Hw1sHbe8rbtuN0mOAY4Frt3/1iRJ+2rQJ1RXAl+pqqf2NJhkVZLRJKNjY2MD3rQk6Rn9hPsDwMJxywu66/ZkJXs5JFNVa6tquKqGh4aG+u9SkjQp/YT7emBxkmOTzKMT4CMTi5K8EjgCuGmwLUqSJqtnuFfVTuA84GrgLuCKqtqYZHWS5eNKVwLrqqqmplVJUr96fhQSoKquAq6asO4jE5YvGlxbkqT94TdUJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqUF/hnmRZkruTbE5ywbPUvCvJpiQbk3xpsG1KkiZjbq+CJHOANcDbgG3A+iQjVbVpXM1i4ELgjVX1WJKXTlXDkqTe+tlzXwpsrqotVbUDWAesmFBzLrCmqh4DqKqHB9umJGky+gn3o4Gt45a3ddeNdzxwfJIbk9ycZNmeHijJqiSjSUbHxsb2rWNJUk+DOqE6F1gMnAKcCXw2yeETi6pqbVUNV9Xw0NDQgDYtSZqon3B/AFg4bnlBd91424CRqnqyqr4L3EMn7CVJM6CfcF8PLE5ybJJ5wEpgZELN1+jstZNkPp3DNFsG2KckaRJ6hntV7QTOA64G7gKuqKqNSVYnWd4tuxr4QZJNwHXAn1bVD6aqaUnS3qWqZmTDw8PDNTo6OiPblqTZKsmGqhruVec3VCWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KD+gr3JMuS3J1kc5IL9jB+dpKxJLd1b787+FYlSf2a26sgyRxgDfA2YBuwPslIVW2aUHp5VZ03BT1Kkiapnz33pcDmqtpSVTuAdcCKqW1LkrQ/eu65A0cDW8ctbwNet4e6dyR5M3AP8KGq2rqHmoF492du2m3db5xwJO95wyJ+suMpzv7cLbuNv/PkBfzW8EIe/dEOPvDFDbuNn/X6Y3j7Lx7Fg4//hA9dfttu4+e+6TjeuuRl3Dv2v/zFV7+92/j5v7qYX148n40Pbmf1lRPf1MCfLfsFTj7mxWy4/1H+/ut37zb+kbcv4dVHHcZ/fecR/vna7+w2/rdnvJZXDP0c39j0fT57w5bdxj/x7l/iqMOfz5W3P8gXb75/t/FPnXUyL37hPL48upWvbNi22/gl71vK8+fN4dKb7uPf7nhot/HLf+8NAKy9/l6uuevhXcYOee4cPv87SwH45DXf4cbNj+wyfsQL5vHp95wMwN99/X/47/sf22X8yMMO4Z9WngjAX125kU0P/nCX8eOGXsjHzjgBgAu/egdbxn60y/iSow7lo29/NQB/uO5WHtr+xC7jJx1zBH++7JUAvP/SDTz24x27jL/x5+fzwVMXA/Dei2/hiSef2mX81Fe9lFVvfgXga8/X3mBee8/MaSoN6oTqlcCiqjoB+E/g83sqSrIqyWiS0bGxsQFtWpI0Uapq7wXJG4CLqurXu8sXAlTVx56lfg7waFUdtrfHHR4ertHR0X1qWpIOVkk2VNVwr7p+9tzXA4uTHJtkHrASGJmwsSPHLS4H7ppMs5Kkwep5zL2qdiY5D7gamANcXFUbk6wGRqtqBPhgkuXATuBR4Owp7FmS1EPPwzJTxcMykjR5gzwsI0maZQx3SWqQ4S5JDTLcJalBhrskNWjGPi2TZAzY/bvK/ZkPPNKzqi3O+eDgnA8O+zPnY6pqqFfRjIX7/kgy2s9HgVrinA8OzvngMB1z9rCMJDXIcJekBs3WcF870w3MAOd8cHDOB4cpn/OsPOYuSdq72brnLknaiwM63Pu4MPfzklzeHf9WkkXT3+Vg9THnP0qyKckdSa5JcsxM9DlIveY8ru4dSSrJrP9kRT9zTvKu7nO9McmXprvHQevjtf3yJNclubX7+j59JvoclCQXJ3k4yZ3PMp4kn+z+PO5IctJAG6iqA/JG578Xvhc4DpgH3A4smVDz+8Cnu/dX0rlI94z3PsVz/hXgBd37HzgY5tytexFwPXAzMDzTfU/D87wYuBU4orv80pnuexrmvBb4QPf+EuC+me57P+f8ZuAk4M5nGT8d+A8gwOuBbw1y+wfynns/F+Zewc8u6fcV4NQkmcYeB63nnKvquqr6cXfxZmDBNPc4aP1egP2vgb8DntjD2GzTz5zPBdZU1WMAVfUws1s/cy7g0O79w4AHp7G/gauq6+lc3+LZrAC+UB03A4dPuPDRfjmQw31PF+Y++tlqqmonsB14ybR0NzX6mfN459D5yz+b9Zxz9+3qwqr69+lsbAr18zwfDxyf5MYkNydZNm3dTY1+5nwRcFaSbcBVwPnT09qMmezv+6T0vBKTDkxJzgKGgbfMdC9TKclzgH/k4Lu611w6h2ZOofPu7Pokr62qx2e0q6l1JnBJVX28e+3mS5O8pqqenunGZqMDec/9AWDhuOUF3XV7rEkyl85buR9MS3dTo585k+StwIeB5VX102nqbar0mvOLgNcA30xyH51jkyOz/KRqP8/zNmCkqp6squ8C99AJ+9mqnzmfA1wBUFU3AYfQ+T9YWtXX7/u+OpDDveeFubvL7+3efydwbXXPVMxS/VyM/ETgM3SCfbYfh4Uec66q7VU1v6oWVdUiOucZllfVbL5GYz+v7a/R2WsnyXw6h2m2TGeTA9bPnL8HnAqQ5FV0wn1sWrucXiPAb3c/NfN6YHtVPTSwR5/pM8o9zjafTmeP5V7gw911q+n8ckPnyf8ysBm4BThupnuehjl/A/g+cFv3NjLTPU/1nCfUfpNZ/mmZPp/n0DkctQn4NrBypnuehjkvAW6k80ma24Bfm+me93O+lwEPAU/SeSd2DvB+4P3jnuM13Z/Htwf9uvYbqpLUoAP5sIwkaR8Z7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNej/APUN9uUS8c/JAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# predict probabilities\n",
    "probs = dt_best.predict_proba(X_test)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "\n",
    "# predict class values\n",
    "y_prd_class_val = dt_best.predict(X_test)\n",
    "\n",
    "# calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, probs)\n",
    "\n",
    "# calculate F1 score\n",
    "f1 = f1_score(y_test, y_prd_class_val)\n",
    "\n",
    "# calculate precision-recall AUC\n",
    "auc = auc(recall, precision)\n",
    "# calculate average precision score\n",
    "ap = average_precision_score(y_test, probs)\n",
    "print('f1=%.3f auc=%.3f ap=%.3f' % (f1, auc, ap))\n",
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0.5, 0.5], linestyle='--')\n",
    "# plot the precision-recall curve for the model\n",
    "pyplot.plot(recall, precision, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEEP NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 0s 498us/sample - loss: 0.6058 - accuracy: 0.8507\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 0s 16us/sample - loss: 0.6023 - accuracy: 0.8550\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 0s 15us/sample - loss: 0.5990 - accuracy: 0.8550\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 0s 15us/sample - loss: 0.5956 - accuracy: 0.8571\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 0s 24us/sample - loss: 0.5923 - accuracy: 0.8657\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 0s 23us/sample - loss: 0.5890 - accuracy: 0.8721\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 0s 14us/sample - loss: 0.5857 - accuracy: 0.8721\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 0s 17us/sample - loss: 0.5824 - accuracy: 0.8742\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 0s 13us/sample - loss: 0.5791 - accuracy: 0.8806\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 0s 28us/sample - loss: 0.5759 - accuracy: 0.8827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1401e4198>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 1: build model\n",
    "model1 = Sequential()\n",
    "#input layer\n",
    "model1.add(Dense(10, input_dim = 10, activation = 'relu'))\n",
    "#hidden layers\n",
    "#output layer\n",
    "model1.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "#step 2: make computational graph - compile\n",
    "opt = SGD(lr=0.01, momentum=0.9)\n",
    "model1.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "\n",
    "#step 3: train the model - fit\n",
    "model1.fit(X_trainval, y_trainval, epochs = 10, batch_size = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSION:  \n",
    "\n",
    "### The file consists of classification  models with:\n",
    "# Hard Voting - Applied on  SVC & KNeighborsClassifier \n",
    "SVC 1.0\n",
    "KNeighborsClassifier 1.0\n",
    "VotingClassifier 1.0\n",
    "SVC 1.0\n",
    "KNeighborsClassifier 1.0\n",
    "VotingClassifier 1.0\n",
    "SVC 1.0\n",
    "KNeighborsClassifier 1.0\n",
    "VotingClassifier 1.0\n",
    "# soft Voting - Applied on Logisitc Regression , KNeighborsClassifier \n",
    "LogisticRegression 1.0\n",
    "KNeighborsClassifier 1.0\n",
    "VotingClassifier 1.0\n",
    "LogisticRegression 1.0\n",
    "KNeighborsClassifier 1.0\n",
    "VotingClassifier 1.0\n",
    "LogisticRegression 1.0\n",
    "KNeighborsClassifier 1.0\n",
    "VotingClassifier 1.0\n",
    "\n",
    "# Bagging \n",
    "## LOGISITC REGRESSION:\n",
    "Train score: 0.99\n",
    "Test score: 0.99\n",
    "\n",
    "   precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00        81\n",
    "           1       1.00      1.00      1.00        76\n",
    "\n",
    "   micro avg       1.00      1.00      1.00       157\n",
    "   macro avg       1.00      1.00      1.00       157\n",
    "weighted avg       1.00      1.00      1.00       157\n",
    "\n",
    "## KNeighborsClassifier\n",
    "Train data\n",
    "Accuracy score:  0.997867803837953\n",
    "f1 score:  0.9978021978021978\n",
    "recall score:  0.9956140350877193\n",
    "precision:  1.0\n",
    "   \n",
    "Test data\n",
    "Accuracy score:  0.9936305732484076\n",
    "f1 score:  0.9933774834437086\n",
    "recall score:  0.9868421052631579\n",
    "precision:  1.0\n",
    "# Pasting\n",
    "## Linear svc\n",
    "Train score: 0.99\n",
    "Test score: 0.99\n",
    "\n",
    "\n",
    "Train data\n",
    "Accuracy score:  0.9829424307036247\n",
    "f1 score:  0.9821428571428572\n",
    "recall score:  0.9649122807017544\n",
    "precision:  1.0\n",
    "   \n",
    "Test data\n",
    "Accuracy score:  0.9745222929936306\n",
    "f1 score:  0.972972972972973\n",
    "recall score:  0.9473684210526315\n",
    "precision:  1.0\n",
    "\n",
    "## Kernel rbf:\n",
    "Train data\n",
    "Accuracy score:  0.997867803837953\n",
    "f1 score:  0.9978021978021978\n",
    "recall score:  0.9956140350877193\n",
    "precision:  1.0\n",
    "   \n",
    "Test data\n",
    "Accuracy score:  1.0\n",
    "f1 score:  1.0\n",
    "recall score:  1.0\n",
    "precision:  1.0\n",
    "\n",
    "# Adaboost \n",
    "Train data\n",
    "Accuracy score:  0.997867803837953\n",
    "f1 score:  0.9978021978021978\n",
    "recall score:  0.9956140350877193\n",
    "precision:  1.0\n",
    "   \n",
    "Test data\n",
    "Accuracy score:  1.0\n",
    "f1 score:  1.0\n",
    "recall score:  1.0\n",
    "precision:  1.0\n",
    "##svc poly\n",
    "\n",
    "Train data\n",
    "Accuracy score:  0.5138592750533049\n",
    "f1 score:  0.0\n",
    "recall score:  0.0\n",
    "precision:  0.0\n",
    "   \n",
    "Test data\n",
    "Accuracy score:  0.5159235668789809\n",
    "f1 score:  0.0\n",
    "recall score:  0.0\n",
    "precision:  0.0\n",
    "\n",
    "\n",
    "# Gradient Boosting -DECISION TREE\n",
    "Train data\n",
    "Accuracy score:  1.0\n",
    "f1 score:  1.0\n",
    "recall score:  1.0\n",
    "precision:  1.0\n",
    "   \n",
    "Test data\n",
    "Accuracy score:  1.0\n",
    "f1 score:  1.0\n",
    "recall score:  1.0\n",
    "precision:  1.0\n",
    "\n",
    "# Deep Neural Network \n",
    "Epoch 1/10\n",
    "469/469 [==============================] - 0s 405us/sample - loss: 0.7721 - accuracy: 0.1620\n",
    "Epoch 2/10\n",
    "469/469 [==============================] - 0s 16us/sample - loss: 0.7652 - accuracy: 0.1684\n",
    "Epoch 3/10\n",
    "469/469 [==============================] - 0s 16us/sample - loss: 0.7582 - accuracy: 0.1791\n",
    "Epoch 4/10\n",
    "469/469 [==============================] - 0s 15us/sample - loss: 0.7516 - accuracy: 0.1876\n",
    "Epoch 5/10\n",
    "469/469 [==============================] - 0s 14us/sample - loss: 0.7448 - accuracy: 0.2068\n",
    "Epoch 6/10\n",
    "469/469 [==============================] - 0s 20us/sample - loss: 0.7383 - accuracy: 0.2281\n",
    "Epoch 7/10\n",
    "469/469 [==============================] - 0s 17us/sample - loss: 0.7316 - accuracy: 0.2495\n",
    "Epoch 8/10\n",
    "469/469 [==============================] - 0s 14us/sample - loss: 0.7250 - accuracy: 0.2623\n",
    "Epoch 9/10\n",
    "469/469 [==============================] - 0s 14us/sample - loss: 0.7185 - accuracy: 0.2857\n",
    "Epoch 10/10\n",
    "469/469 [==============================] - 0s 22us/sample - loss: 0.7120 - accuracy: 0.3006\n",
    "\n",
    "\n",
    "After pca :\n",
    "Epoch 1/10\n",
    "469/469 [==============================] - 0s 498us/sample - loss: 0.6058 - accuracy: 0.8507\n",
    "Epoch 2/10\n",
    "469/469 [==============================] - 0s 16us/sample - loss: 0.6023 - accuracy: 0.8550\n",
    "Epoch 3/10\n",
    "469/469 [==============================] - 0s 15us/sample - loss: 0.5990 - accuracy: 0.8550\n",
    "Epoch 4/10\n",
    "469/469 [==============================] - 0s 15us/sample - loss: 0.5956 - accuracy: 0.8571\n",
    "Epoch 5/10\n",
    "469/469 [==============================] - 0s 24us/sample - loss: 0.5923 - accuracy: 0.8657\n",
    "Epoch 6/10\n",
    "469/469 [==============================] - 0s 23us/sample - loss: 0.5890 - accuracy: 0.8721\n",
    "Epoch 7/10\n",
    "469/469 [==============================] - 0s 14us/sample - loss: 0.5857 - accuracy: 0.8721\n",
    "Epoch 8/10\n",
    "469/469 [==============================] - 0s 17us/sample - loss: 0.5824 - accuracy: 0.8742\n",
    "Epoch 9/10\n",
    "469/469 [==============================] - 0s 13us/sample - loss: 0.5791 - accuracy: 0.8806\n",
    "Epoch 10/10\n",
    "469/469 [==============================] - 0s 28us/sample - loss: 0.57\n",
    "\n",
    "\n",
    "## The Deep Neural networks show a drastic change in accuracy before and after pca\n",
    "\n",
    "\n",
    "#### The boosting algorithms were applied on the previous project models with best parameters to reduce the error in the model..There is not much change in the results from the previous project. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
